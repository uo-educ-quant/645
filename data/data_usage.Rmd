---
title: "Data usage and etc"
author: "Claire Zhang"
output: html_document 
date: '2022-08-02'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      include = TRUE,
                      message = FALSE)
pacman::p_load(tidyverse, janitor, rio, here, gtsummary)
theme_set(hrbrthemes::theme_ipsum())

```

# 1. Unit 1 Logistic Regression

## 1.1 Lecture and/or lab slides (school principal data)

### 1.1.1 Inspecting/managing data

This dataset was drawn from Meta Kr√ºger's (1994) study investigating gender differences in school leadership in Netherlands. The study implemented a matching procedure to generate pairs of comparable schools (N=98) with the only difference being that one school principal was female and the other male, then surveyed the school principals, teachers, and students. Due to deletion of incomplete observations, our dataset is a bit smaller than the one used in the article, it contains 94 school principals and 800 students.

```{r}
principal <- rio::import(here::here("data", "principal.csv")) %>%
  mutate(attention = (q1+q2+q3)/3,
         affective = ifelse(q4 >= 3, 1, 0)) %>% 
  select(schid, stuid, stufemale, female, match, attention, affective) %>% 
  group_by(schid) %>% 
  mutate(attention = (attention-mean(attention))/sd(attention)) %>% 
  ungroup() 

head(principal)
```

The dataset contains nine variables, detailed below.

 - schid, school identification number
 - stuid, student identification number within each school
 - female, coded one for female principals and zero for male principals
 - stufemale, coded one for female students and zero for male students
 - match, coded one if student and principal are the same gender
 - q1, students' rating on a survey item, "Sometimes the principal talks to me", on a 4-point likert scale, 1=low, 4=high
 - q2, students' rating on a survey item, "I think the principal knows who I am", on a 4-point likert scale, 1=low, 4=high
 - q3, students' rating on a survey item, "Principal knows how well I am doing", on a 4-point likert scale, 1=low, 4=high
 - q4, students' rating on a survey item, "The principal is nice", on a 4-point likert scale, 1=low, 4=high
 
For starters, some data managment; we're interested in the association between student-perceived attention from principal and affective attitude toward principal, therefore we compute two variables of interest:

 - attention: take the average score of attention items, q1, q2, and q3, then standardize it at school level to measure student-perceived attention
 - affective: recode q4 to be a binary variable coded one for students who rated 3 or 4 on this question ("the school principal is nice")
 
### 1.1.2 Visualizing the relationship
 
Plot outcome variable, affective, on predictor variable, attention:

```{r}
principal %>% 
  mutate(affective = recode(affective, '1' = "Yes", '0' = "No")) %>% 
  ggplot(aes(attention, affective, color = affective)) +
  geom_boxplot(size = 0.5) +
  geom_jitter(alpha = 0.2,
              size = 0.5) + 
  scale_x_continuous() + 
  labs(y = "Affective attitude towards principal",
       x = "Self-perceived attention from principal") +
  theme(legend.position = "none") 
```

What patterns do you notice from the plots above?


### 1.1.3 Modeling the relationship

How to model these relationships in our analysis?
Our inquiry: The associations between student self-perceived attention from principal and affective attitude towards principal.

What models should we use to fit the data when our outcome variable is a dichotomous variable?

#### Linear probability model (LPM)

```{r}
m1 <- lm(affective ~ attention, principal)
m2 <- lm(affective ~ attention + match, principal)
summary(m1)
```

Does the regression coefficient of attention confirm your previous impression with the plot?

Visualize the coefficient/slope of the fitted line (basically, we force the relationship to be linear):

```{r}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(alpha = 0.01) +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") + 
  labs(y = "Affective attitude towards principal",
       x = "Self-perceived attention from principal")
```


Interpret the results (report regression coefficients **on a probability scale**) and the figure. 

Will this be the model where you stop at?

#### Binomial logistic regression

```{r}
m3 <- glm(affective ~ attention, principal, 
          family = binomial(link = "logit"))
m4 <- glm(affective ~ attention + match, principal,
          family = binomial(link = "logit"))

summary(m3)
```

Visualize the coefficient on a log-odds scale (basically we model the change in log-odds of affective in a linear function of attention):

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = .)) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (LOG-ODDS)",
       x = "Self-perceived attention from principal")
```


Visualize the coefficient on a probability scale (mapping the parameters to probability nonlinearly):

Coder note: in the data, "attention" ranges from -2.42 to 2.61, the plot is therefore limited to a fraction when the probability of "affective" approaching one but still below 0.5. Because we cannot easily guess the missing plot fraction (as appose to when the line is linear, we can tell where the line goes simply by looking at the slope), this plot is not telling us enough information about the population of interest:

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```


I manipulate the X axis to range from -3 to 15 to show the nonlinear relationship in its full image:

```{r}
tibble(attention = (-3):15) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```

Interpret the results (report regression coefficients **on a log-odds scale**) and the two figures.

### 1.1.4 Comparing models 

Putting models together and report them in a table:

```{r}
huxtable::huxreg(
  "LPM" = m1, 
  "LPM" = m2,
  "Logistic" = m3,
  "Logistic" = m4,
  coefs = c("Attention" = "attention",
            "Matched gender" = "match")
)
```

There is an on going conversation about LPM versus logistic regression.

https://github.com/alexpghayes/linear-probability-model/blob/master/presentation.pdf

## 1.2 Unit 1 Assignment (nscs.csv)

To gain a broad picture of the counselor experience during the early months of COVID-19 school closures, Savitz-Romer and Rowan-Kenyon (2021) created an 80-question online survey to collect data from 1,060 school counselors and educators in adjacent roles (e.g., college counselors, adjustment counselors, counseling directors) in 48 states and Puerto Rico in the US. The publicly available dataset has 28 variables. For simplicity reason, we only include several variables as following:

 - id, counselor identification number
 - grades, school level, 0 = elementary, 1 = middle school, 2 = high school, 3 = mixed
 - schooltype, school type, 1 = public, 2 = charter, 3 = private
 - urbanicity, school urbanicity level, 1 = urban, 2 = suburban, 3 = rural
 - female, counselor gender coded one for female and zero for others
 - exp, counselor experience measured by years
 - ooo, dichotomous variable coded one if the counselor had less time for one-on-one counseling due to COVID 
 - group, dichotomous variable coded one if the counselor had less time for group counseling due to COVID 
 - sel, dichotomous variable coded one if the counselor had less time for supporting student social emotional needs due to COVID 

```{r}
nscs <- rio::import(here::here("data", "nscs.csv")) 
```


### Assignment objectives

You're interested in *which counselor or school characteristic is significantly associated with reduced counseling service during the early stage of COVID pandemic*.

Conduct a brief literature review on how the pandemic impacted school counseling programming, with a focus on which counselor characteristic (gender OR years of experience) or school characteristic (school level OR type OR urbanicity) was significantly associated with reduced counseling services (one-on-one counseling OR group counseling OR supporting student social emotional needs). Based on your research, identify a research question that uses one of the three "reduced counseling services" measures as outcome variable. Write up your reasoning in a short paragraph that is ended with your specified research question (10% points).  

Load the "nscs.csv" dataset and perform basic data management:

 - only keep variables that you think will be used in your analysis and drop other variables
 - drop incomplete observations
 - check whether your variables are the right class (e.g., you want id and school variables to be factor rather than double), if not, convert them to the right type
 - other data management you think fit 
 - produce a summary statistics table (10% points)

Model the relationship of your interest in a linear probability model, visualize the relationship between the two variables (10% points), report and interpret the coefficients and the plot (10% points). Add covariates and see if your estimates change (10% points). 

Model this relationship in a logistic regression model, visualize the relationship between the two variables (10% points), report and interpret the coefficients and the plot. Add covariates and see if your estimates change (10% points).
 
Write a short paragraph (supplement it with an APA table, 10% points) to compare the models, summarize your findings, and discuss limitations (30% points).


# 2. Unit 2 Poisson Regression 

## 2.1 Lecture and/or lab slides (potentially nscs.csv)


# 3. Unit 3 Nested Data 

Load the packages particularly needed for this unit,

```{r}
pacman::p_load(lme4, equatiomatic, performance, lmerTest)
```

## 3.1 Lecture and/or lab slides (seda_oregon.csv)

This dataset was drawn from the Stanford Education Data Archive (SEDA) version 4.1. 

SEDA was launched in 2016 to provide nationally comparable, publicly available test score data for U.S. public school districts, allowing scientific inquiries on the relations between educational conditions, contexts, and outcomes (especially student math/ELA achievements) **at the district-level** across the nation. It contains rich variables including measures of academic achievement and achievement gaps for school districts and counties, as well as district-level measures of racial and socioeconomic composition, racial and socioeconomic segregation patterns, and other features of the schooling system.

Due to the large size of SEDA full data set, we focus on the school year 2017-18 data for the state of Oregon. Specifically, our data set is district-level data for 103 Oregon school districts. Observations with missing values on any of the key variables were deleted for simplification reasons.

The data set contains eight variables, detailed below.

 - district, name of the district
 - subject, coded ‚Äúmth‚Äù fo Mathematics and ‚Äúrla‚Äù for Reading/Language Arts
 - grade, coded 3, 4, 5, 6 for grades 3-6
 - achievement, grade-level average achievement test score
 - gap_gender, grade-level male-female gender gap on achievement test
 - percent_ell, district-level percentage of ELL students
 - percent_sped, district-level percentage of students in special education program
 - percent_frl, district-level percentage of students eligible for free or reduced school lunch
 
**Potentially, two outcomes variable candidates here: achievement (my choice now) and achievement gender gap; three predictor variable candidates (three "percent_" variables), I'll use percentage of ELL students in this sheet.**
**If this combo is used in the lecture, other combos can be explored in the labs and vice versa.**

### 3.1.1 Inspect the data 

What does each row/observation represent?

Notice the district-by-subject-by-grade nature.

```{r}
seda <- rio::import(here::here("data", "seda_oregon.csv")) %>%
  mutate(subject = recode(subject, 'mth' = "Math", 'rla' = "Reading")) 

str(seda)
head(seda)

seda %>%
  select(-district) %>% 
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} / {N} ({p}%)"),
    label = list(subject ~ "Subject",
                 grade ~ "Grade",
                 achievement ~ "Achievement",
                 gap_gender ~ "Achievement Gender Gap",
                 percent_ell ~ "ELL Percentage",
                 percent_sped ~ "SPED Percentage",
                 percent_frl ~ "FRL Percentage")) %>%
  modify_header(label ~ "**Key Variables**")
```


### 3.1.2 Understand the clustering nature

For starters, look at a single variable - Oregon districts' achievement score 

(note that districts are "randomly" selected by course developer)

Are we losing information by simply looking at district achievement across subject and grade?

```{r}
seda %>% 
  group_by(district) %>% 
  mutate(mean = mean(achievement)) %>%
  ungroup() %>% 
  select(district, mean) %>%
  ggplot(aes(district, mean)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```


Does achievement differ by subject?

```{r}
seda %>% 
  group_by(district, subject) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, mean) %>%
  ggplot(aes(district, mean, color = subject)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

Differ by grade?

```{r}
seda %>% 
  group_by(district, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, grade, mean) %>%
  ggplot(aes(district, mean, color = grade)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

Differ by grade AND subject?


```{r}
seda %>% 
  group_by(district, subject, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, grade, mean) %>%
  ggplot(aes(district, mean, color = grade)) +
  facet_wrap(vars(subject)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

Alternatively, 

```{r}
seda %>% 
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6")) %>% 
  group_by(district, subject, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, grade, mean) %>%
  ggplot(aes(district, mean, color = subject)) +
  facet_wrap(vars(grade)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

Can you describe the "clustering" nature of the data in more details now?

IMPORTANTLY, should we keep in mind of this unique feature when we answering research questions, e.g., about relations between two variables?

For example, let's look at relationship between percentage of ELL and achievement

Relationship across grade and subject:

```{r}
seda %>%
  group_by(district) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) + 
  labs(x = "ELL Percentage",
       y = "Achievement")
```


Does this relationship differ by subject?

```{r}
seda %>%
  group_by(district, subject) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement, color = subject)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Achievement")
```


Does this relationship differ by subject AND grade?


```{r}
seda %>%
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6")) %>% 
  group_by(district, subject, grade) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement, color = subject)) +
  facet_wrap(vars(grade)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Achievement")
```


What is your current understanding of clustered data? Is there a single answer to the relationship between percentage of ELL students and achievement? 

(expect students to realize that there is no universal answer; depends on what you look at, what cluster/clusters you want to include, and model specifications)


### 3.1.3 Modeling the relationship between two variables

**For this introductory course, we only focus on two-level clustered data.**

From now on, we pull out the cluster of subject, and focus on math achievement only.

**Overarching inquiry: What is the relationship between percentage of ELL students and math achievement in Oregon districts?**


```{r}
district <- seda %>%
  filter(subject == "Math") %>% 
  select(-subject) %>% 
  select(math = achievement, everything()) %>% 
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6"))
```

What model/models can we fit to answer the question? 

#### Fixed effects model

One way to answer the question is assuming a common intercept for all grades. 

Visually:

```{r}
district %>% 
  ggplot(aes(percent_ell, math)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Math")
```


Model specifications (using multiple regression knowledge you learned from EDUC 643, you can do it!):

```{r, echo=TRUE}
m1 <- lm(math ~ percent_ell, district)
summary(m1)
coef(m1)
```

How to interpret these parameters?

#### Random effects model

Another way to answer the question is allowing the intercept to differ across grades - a unique intercept for each grade.

Visually:

```{r}
district %>% 
  ggplot(aes(percent_ell, math, color = grade)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) + 
  labs(x = "ELL Percentage",
       y = "Math")
```

What parameters changed in the plot? 

 - the intercept: each grade has a unique intercept

 - the slope: the slope also changes accordingly
 
 
**In fact, mixed-effects models can do more!** 

let's take advantage of the lme4 package, lmer function to quickly model the data in R:

 - Model 1. Put the simple linear regression model here for comparison
 
```{r}
m1 <- lm(math ~ percent_ell, district)

coef(m1)
```

 - Model 2. Multilevel model with random intercepts 
 
      - What parameter differs across grades? what parameter remains the same?
      - Interpret the parameters

*R notes: starting the basics of the lme4::lmer() syntax*

```{r, echo=TRUE}
m2 <- lme4::lmer(math ~ percent_ell + (1|grade), district)
summary(m2)
coef(m2)$grade
```

*R Notes: starting the usage of {equatiomatic} package*

The notion being used through this unit:

```{r}
equatiomatic::extract_eq(m2)
```



 - Model 3. Multilevel model with random slopes 
 
      - (note that this is a weird practice in real data analysis but here I just include it for comparison purposes)
 
      - How do you interpret the parameters now?
 
```{r, echo=TRUE}
m3 <- lmer(math ~ 1 + (0 + percent_ell|grade), district)
summary(m3)
coef(m3)$grade
# extract_eq(m3) doesn't work here
```
    
 - Model 4. Multilevel model with random intercepts and slopes 
 
      - How about the parameters for this model specification?
      - Can you specify the relationship between percentage of ELL and math achievement for grade 3? grade 4? .. grade 6?

```{r, echo=TRUE}
m4 <- lmer(math ~ percent_ell + (1 + percent_ell|grade), district)
summary(m4)
coef(m4)$grade
extract_eq(m4)
```

What did we learn so far? Describe the differences between model 1 (simple linear regression) and a model with

 - Random intercepts, model 2
 - Random slopes, model 3
 - Random intercepts and slopes, model 4


### 3.1.4 Fixed effects vs random effects

If we put the two previous plots together, can you describe:

 - what does the bright red line represent? 
 - what do the other four lines represent? 

```{r}
district %>% 
  ggplot(aes(percent_ell, math)) +
  geom_smooth(method='lm', se = 0, color = "deeppink") +
  geom_point(alpha = 0.1) + 
  geom_smooth(aes(color = grade), method='lm', se = 0) +
  geom_point(aes(color = grade), alpha = 0.1) +
  scale_color_hue(l=80, c=30) +
  labs(x = "ELL Percentage",
       y = "Math")
```

Also a review of the relationship between fixed effect (model 1) and random effects (model 4) parameters:

Run the code for yourself and see what you notice:

```{r}
coef(m1)[1]
mean(unlist(coef(m4)$grade[1]))
```

Run the code for yourself and see what you notice:

```{r}
coef(m1)[2]
mean(unlist(coef(m4)$grade[2]))
```

What might be the reason behind these?

To sum up:

 - fixed effect represents the aggregation of the different intercepts and slopes by taking an average of varying intercept and slopes across clusters
 
 - random effects represent the difference between cluster-specific intercept and slope and their averages across clusters
 
### 3.1.5 When modeling random effects becomes necessary?

#### Unconditional model and ICC

We estimate a baseline model, model 0, to see how much variance in math is attributable to between-grade variation

*R notes: starting the {performance} package usage*

```{r}
m0 <- lmer(math ~ 1 + (1 | grade), district)
extract_eq(m0)
summary(m0)
performance::icc(m0)
```

*ICC: intraclass correlation coefficient*

Specifically, about 64.5% of the variance in math achievement lies between grades. 

At this point, the fixed effects model aggregating grade-level achievement to a grand mean is masking important information regarding grade-level achievement.
 
allow you to investigate changes over time

#### Model fit 

So far, we have one fixed effects model (simple linear regression, model 1) and four random effects (more accurately, mixed-effects) models including the unconditional model (model 0), random intercepts (model 2), random slopes (model 3), and random intercepts and slopes (model 4). 

How do we know which one is preferred?

(from Dr. Daniel Anderson's multilevel modeling II course)

  - RMSE
  - Chi squared significance test of the change in the model deviance
  - Information criteria (AIC/BIC)
  - Cross validation procedures

For example, comparing model 1 and model 4:

```{r}
performance::compare_performance(m1, m4) %>% 
  print_md()
```


```{r}
test_likelihoodratio(m1, m4) %>% 
  print_md
```

Another example, comparing model 2 and model 4:

```{r}
performance::compare_performance(m2, m4) %>% 
  print_md()
```


```{r}
test_likelihoodratio(m2, m4) %>% 
  print_md
```

Definitely prefer model 4 over model 1; 

But model 4 doesn't perform much better than model 2 (identical RMSE; insignificant chi squared test of the change in the model deviance; also visually confirmed in the previous random-intercept random-slope plot that the slope of the fitted line didn't vary too much across four grades), so for this little exercise, I would choose model 2 for parsimonious reason.

## 3.2 Unit 3 Assignment (gpa.csv)

The GPA data is a longitudinal dataset, where 200 college students were followed for six consecutive semesters. The data was simulated. Key variables are detailed below.

 - stuid, student identification number
 - time, a factor variable indexing the six consecutive semesters
 - gpa, student's GPA at the end of semester
 - female, a dichotomous variable coded one for female students and zero for male
 - hsgpa, high school GPA
 
 
```{r}
gpa <- import(here("data", "gpa.csv")) %>% 
  drop_na()

head(gpa)
```
 
### Assignment goal: investigating change over time

### Assignment objectives and points allocation:

Load the "gpa.csv" dataset and perform basic data management

 - check whether the variables are the right class (e.g., you want stuid to be factor rather than double), if not, convert them to the right type
 - other data management you think fit (e.g., you may want to recode female to be "Female" and "Male" instead of one and zero if you want a nice summary statistics table)
 - produce a summary statistics table (10% points)
 
Across all semesters, what is the overall relationship between student high school GPA and the semester GPA? 

 - specify your model, report and interpret your results (10% points)
 - visualize this relation in a plot with fixed intercept and slope (10% points)
 - visualize this relation in a plot with intercepts and slopes corresponding to the six semesters (10% points)

What about the change in GPA over time? 

 - specify your unconditional model, report and interpret your results (10% points)
 - identify how much variance in GPA is due to between-semester variation (10% points)

Multilevel modeling to investigate the role time plays in this relation 

 - specify at least two random-intercept and/or random-slope models, report and interpret the results for each model (20% points)
 - compare model performance of the two models, which is your preferred model? why? (10% points)
 
Discussion

 - write a short paragraph (supplement it with an APA table?) to summarize your findings and highlight how time plays a role in the relation between high school GPA and semester GPA (10% points)

# 4. Unit 4 Measurement and Assessment

# 5. Unit 5 Dealing with Missing Data

## 5.1 Lectures and/or Labs (galo.csv and/or nscs.csv)

The GALO data is originally described by Peschar (1975) and analyzed by Dronkers and Schijf (1994) among other studies. The 1959 cohort consists of 1270 school children in the sixth grade of 37 elementary schools in the city of Groningen (Netherlands). We have two candidates for outcome variables, "galo" (student's achievement score on GALO tes) and "advice" (teacher's advice on the student's secondary school choice, potentially based on the students' overall performance). The former has no missing but latter contains 0.45% missing values.

Key variables are detailed below.

 - schid, school identification number
 - female, coded one for female students and zero for male
 - galo, student's achievement score on GALO test
 - advice, teacher‚Äôs advice on the student's secondary school choice; 0="no subsequent school", 1="lowest",..., 6="highest", 999="missing" 
 - medu, mother's highest education; 1="lowest",..., 9="highest", 999="missing"
 - fedu, father‚Äôs highest education; 1="lowest",..., 9="highest", 999="missing"
 - focc, father‚Äôs occupational status; 1="lowest",..., 6="highest", 9="missing"

```{r}
galo <- import(here("data", "galo.csv"))
```


```{r}
#I understand we don't want introduce students to the functional programming world
# I'm in searching  for an easier way to report missing values that can be more accessible to students
missing <- function(data){
  na_percentage <- function(x){
    y = sum(is.na(x))/length(x)
    paste(round(100*y, 2), "%", sep="")
  }
  apply(data, 2, na_percentage)
}

missing(galo)
```

Missingness in the nscs.csv used in Unit 1 assignment:

```{r}
missing(nscs)
```


About assignment: maybe no assignment for this unit because not only students have final project to engage, but also the content of this unit is a data management tool rather than method/data modeling.

# 6. Final project 

### 6.1 Introduction

The final project for this course will serve as a capstone project where students apply their knowledge and skills obtained from mainly this, but also other two quant sequence courses. Students should pick a specific research question of interest, find a dataset, perform data management, data analysis, report findings, and write a short technical report that is appealing to general audience. 

Three critical strategies to help students succeed:

 - locating the right dataset: students can search on their own from the resources provided below but one-on-one check in might be needed to make sure their data will work for them and set them off on the right track
 - oral proposal: by week five, students should meet with instructional team to propose their research question(s), dataset and measures, methods
 - peer support system: although the final is individual, it'll be super helpful to put students with similar research interests into study groups (I can see the value of this starting from week 1; not only for final project, but for doing assignments together) 

### 6.2 Requirments:

(from Dr. Cengiz Zopluoglu's EDUC 614 course)

 - Introduction: briefly provide a context and background and describe variables in your study. The introduction should also include a written research question that can be answered using one of the methods discussed in the class.
 - Method: This section should describe the sample and dataset by providing the descriptive statistics of the sample characteristics and independent and dependent variables. This section should also mention the type of analysis you plan to use for answering your research question.
 - Results: This section should provide a written summary of your results and interpretation of your statistical analysis, supplemented by APA style formatted tables and figures. If you can‚Äôt fit the table and figures into the 3-page limit, you can provide them in the Appendix.
 - Appendix: This section should include all the SPSS output or R syntax/output as an appendix for reference (this is not included in the 3-page limit).
 
### 6.3 Data Sources

(from Dr. Cengiz Zopluoglu's EDUC 614 course)

 - Google Dataset Search: https://datasetsearch.research.google.com
 - ICPSR/Inter-university Consortium for Political and Social Research: https://www.icpsr.umich.edu/web/pages/ICPSR/index.html
 - NCES Blog post on data tools: https://nces.ed.gov/blogs/nces/post/data-tools-for-college-professors-and-students1
 - Mendeley Data on education: https://data.mendeley.com/research-data/?search=education
 - PISA: https://www.oecd.org/pisa/
 - TIMSS & PIRLS: https://timssandpirls.bc.edu




