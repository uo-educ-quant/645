---
title: "Analyzing Count Outcomes 1"
subtitle: "EDUC 645 (Unit 3)"
#author:
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  editor_options: 
  chunk_output_type: console
---

```{R, setup, include = F}
library(pacman)
p_load(NHANES, easystats, emmeans, DHARMa, ggeffects,
       here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, lfe, arsenal, ggpubr, stargazer, fixest, gtsummary, huxtable, aod)

i_am("slides/EDUC645_3_PoissonNB1.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 5,
  fig.width = 8,
  warning = F,
  message = F
)

NHANES_data1112 <- NHANES::NHANES %>% 
  select(ID, SurveyYr, Gender, Age, AgeDecade, Race3, Education, Poverty, Diabetes, DaysMentHlthBad, Depressed, PhysActive, SleepTrouble, SleepHrsNight) %>% 
  mutate(Race_Eth = as_factor(case_when(Race3 == "Mexican" | Race3 == "Hispanic" ~ "Hispanic/Latino",
                                        TRUE ~ Race3)),
         PhysActive = as_factor(case_when(PhysActive == "No" ~ "Inactive",
                                          PhysActive == "Yes" ~ "Active")),
         PhysActive = factor(PhysActive, levels = c("Active", "Inactive")),
         DaysMHBad_most = as_factor(case_when(DaysMentHlthBad < 10 ~ "No",
                                              DaysMentHlthBad >= 10 ~ "Yes")),
         DaysMHBad_most = factor(DaysMHBad_most, levels = c("No", "Yes"))) %>% 
  rename(Depress_Freq = Depressed, Sex = Gender, DaysMHBad_count = DaysMentHlthBad, Sleep_Trouble = SleepTrouble) %>% 
  select(ID, SurveyYr, Age, Sex, Race_Eth, Diabetes, Depress_Freq, PhysActive, DaysMHBad_count, DaysMHBad_most, 
         Sleep_Trouble, SleepHrsNight) %>%   
  filter(SurveyYr == "2011_12", Age > 12) %>% 
  filter(if_all(everything(), ~!is.na(.))) %>% 
  select(-SurveyYr)
```


---
# Unit Overview

Week 1 (slide set #1)

- Recap of count outcome concepts

- Basic regression model fit, diagnostics, and interpretation for count outcomes


--
Week 2 (slide set #2)

- Analyzing counts in nested data


---
# Recap: What makes a count outcome a count?

Counts indicate how many of an outcome are present, or often, how many of an outcome are present *in a specific timeframe* (aka a *rate*).


--
In addition, a distribution of counts is:


--
- Usually *skewed*, meaning that some values are much more common than others - often a lot, or none at all (zero).


--
- Often *overdispersed*, which means the counts vary more than would be expected.


--
Counts/rates require analyses that account for these properties. These methods are similar to those used for dichotomous outcomes (remember that another way of thinking of counts is that they measure a series of dichotomous outcomes).


---
# Normally distributed data

We previously looked at a more normally distributed variable from NHANES: `SleepHrsNight`, the self-reported number of hours of sleep a participant usually gets.


--
```{r, warning=FALSE, fig.retina=3}
NHANES_data1112 %>% 
  ggplot(aes(SleepHrsNight)) +
  geom_histogram(binwidth = 0.5)
```


---
# Count data

`DaysMHBad_count`, the number of days per month an NHANES participant reports experiencing poor mental health.


--
```{r, warning=FALSE, fig.retina=3}
NHANES_data1112 %>% 
  ggplot(aes(DaysMHBad_count)) +
  geom_histogram(binwidth = 1)
```


---
class: middle, inverse

# Analyzing count data

---
# Options for analysing count data


--
<span style = "color:green"> Linear regression: </span>Count outcome variables are sometimes log-transformed and analyzed using OLS regression. 


--
- Many issues in addition to violating model assumptions, including biased estimates and loss of data because it is necessary to take the log of zero (which is undefined).


--
<span style = "color:green"> Poisson regression: </span>Often used for modeling count data. 


--
<span style = "color:green"> Negative binomial regression: </span>Similar to Poisson regression, but relaxes a restrictive assumption (to be discussed in a few slides).


--
<span style = "color:green"> Zero-inflated regression model: </span>Used to account for excess zeros produced by a different process from "true" zeros. 


---
# Assessing variability

We can get a preliminary sense of whether overdispersion is present by comparing the mean and variance of the `DaysMHBad_count` variable we looked at earlier. Here we'll limit the data to participants 16 or older because the independent variable we'll look at shortly was not measured in participants under 16.


--
```{r}
NHANES_data1112 %>% 
  filter(Age >= 16) %>% 
  summarize(mean = mean(DaysMHBad_count),
            variance = var(DaysMHBad_count))
```


--
The variance of the counts far exceeds the mean, suggesting overdispersion. We'll formally assess overdispersion of model *residuals* once we've fitted our models. 


--
This said, these values are a good indication that we should go with negative binomial regression, but we'll compare it against a Poisson regression model to confirm. 


---
# Fitting a model

Here, we'll look at whether there is a relationship between participants' self-reported sleep quality (`Sleep_Trouble`) and the number of days per month they have poor mental health (`DaysMHBad_count`). To fit a negative binomial model we'll use the `glm.nb` function from the MASS package (included with R).

--
```{r}
library(MASS)
mod_1 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble, 
                data = NHANES_data1112)
```


--
Fitting a comparable Poisson model for a comparison of fit. 

```{r}
mod_1b <- glm(DaysMHBad_count ~ Sleep_Trouble, family = poisson(),
              data = NHANES_data1112)
```

---
# Fitting a model

--
.pull-left[
**Deviance:**

```{r}
mod_1b$deviance # Poisson
mod_1$deviance # Neg Binom
```
]


--
.pull-right[
**AIC:**

```{r}
mod_1b$aic # Poisson
mod_1$aic # Neg Binom
```
]


--
And most critically, we can see that the Poisson gave us much smaller standard errors, which would produce artificially narrow confidence intervals. 

```{r}
summary(mod_1b)$coefficients[2, "Std. Error"] # Poisson
summary(mod_1)$coefficients[2, "Std. Error"] # Neg Binom
```


---
# Fitting a model

We can also look at whether the negative binomial model better accounts for overdispersion. We'll use the DHARMa package again. 


--
```{r}
mod_1_residuals <- simulateResiduals(mod_1)
testDispersion(mod_1_residuals, 
               alternative = "greater", plot = F)
```


--
Compared with the Poisson:

```{r, echo=FALSE, include=FALSE}
mod_1b_residuals <- simulateResiduals(mod_1b)
mod_1b_residuals_p <- testDispersion(mod_1b_residuals, 
                                     alternative = "greater", plot = F)
```


--
.pull-left[
```{r}
mod_1b_residuals_p$statistic
```
]


--
.pull-right[
```{r}
mod_1b_residuals_p$p.value
```
]

---
# Basic interpretaton 

Like logistic regression, we have to exponentiate the model coefficients to interpret the results. With counts, the exponentiated coefficient is a **rate ratio**.


--
```{r}
mod_1 %>% 
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)
```


--
- Compared with participants who do not have trouble sleeping, participants who have trouble sleeping on average experience 2.13 times as many days per month with poor mental health (95% CI [1.78, 2.57]). 


--
- On average, participants who have trouble sleeping experience 113% more poor mental health days each month (95% CI [1.78, 2.57]) than participants who do not have trouble sleeping.


---
# Assignment 3


--
Assignment 3 will be a group presentation activity. You'll choose an article that used some of the methods from the course, critically evaluate it, then present a summary of the article along with your observations in class during Week 10. 


--
- **Brondolo 2015:** Perceived ethnic discrimination and cigarette smoking: Examining the moderating effects of race/ethnicity and gender in a sample
of Black and Latino urban adults


--
- **Caceres 2015:** Cardiovascular disease risk in sexual minority women
(18-59 years old): Findings from the National Health and
Nutrition Examination Survey (2001-2012)


--
- **Poulson 2020:** Intersectional disparities among Hispanic groups in COVIDâ€‘19
outcomes


--
- **Tanner 2015:** Factors influencing health care access perceptions and care-
seeking behaviors of immigrant Latino sexual minority men and transgender individuals: Baseline findings from the HOLA intervention study


--
Detailed instructions will be sent via Canvas. Articles are now in the Files tab on Canvas.

---
class: middle, inverse

# From here, we proceed like logistic regression...

---
# First we fit a null model

```{r}
mod_0 <- glm.nb(DaysMHBad_count ~ 1, 
                data = NHANES_data1112)
```


---
# Adding independent variable

We fit the next model (with the `Sleep_Trouble` independent variable) on an earlier slide. Unsurprisingly, it fits better than the null model:

--
```{r}
anova(mod_0, mod_1, test ="Chisq")
```

--
```{r}
mod_0$aic
mod_1$aic
```

---
# Adding covariates

Adding `Age` as a covariate:


--
```{r}
mod_2 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age, 
                data = NHANES_data1112)
anova(mod_1, mod_2, test ="Chisq")
```


--
```{r}
mod_1$aic
mod_2$aic
```

---
# Adding covariates

Adding `Sex` as a covariate:


--
```{r}
mod_3 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age + Sex, 
                data = NHANES_data1112)
anova(mod_2, mod_3, test ="Chisq")
```


--
```{r}
mod_2$aic
mod_3$aic
```

---
# Adding an interaction

```{r}
mod_3_int <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age + Sex + 
                      Sleep_Trouble:Sex, data = NHANES_data1112)
```

--
Evaluate the significance of the interaction (no need to exponentiate):

```{r}
mod_3_int %>% 
  broom::tidy() 
```


---
# Assumptions and diagnostics

Since the interaction term was significant, we'll check fit and assumptions before proceeding to interpretation.

```{r}
anova(mod_3, mod_3_int, test ="Chisq")
```


--
```{r}
mod_3$aic
mod_3_int$aic
```


---
# Assumptions and diagnostics

We can then use the same tools to assess model assumptions as we used in logistic regression. 

--
```{r, fig.retina=3}
mod_3_int_residuals <- simulateResiduals(mod_3_int, n = 1000) 
plot(mod_3_int_residuals)
```


---
# Assumptions and diagnostics

The two-sided dispersion test in the plot was significant, but remember we are mainly interested in overdispersion. So we can specify a one-sided test for overdispersion using the same function as we used several slides ago. 

--
```{r}
testDispersion(mod_3_int_residuals, alternative = "greater", plot = F)
```

                                     
---
# Assumptions and diagnostics

We can also formally test for zero inflation, again using DHARMa:

```{r}
testZeroInflation(mod_3_int_residuals, plot = FALSE)
```


--
Even if the test had been significant, is our outcome one where there could be plausible mechanisms for excess zeros?

---
# Assumptions and diagnostics

Checking multicollinearity visually using the `check_model()` function from the *performance* package.

```{r, warning=FALSE, fig.retina=3}
performance::check_model(mod_3_int, check = "vif")
```


---
# Interpreting an interaction

Finally, we can interpret the interaction using predicted *counts*, just like we used predicted probabilities in logistic regression.


--
```{r}
# using the ggeffects package
mod_3_int_probs <- predict_response(mod_3_int,
                                    type = "fe",
                                    terms = c("Sleep_Trouble", "Sex"),
                                    margin = "marginalmeans")
```

---
# Interpreting an interaction

```{r}
print(mod_3_int_probs)
```

---
# Interpreting an interaction

```{r, fig.retina=3}
plot(mod_3_int_probs)
```

---
# Interpreting an interaction


--
Participants with trouble sleeping would be expected to have significantly more poor mental health days each month than participants without sleeping trouble, regardless of participant sex.


--
In contrast, among participants who did not report sleeping trouble, female participants would be expected to have significantly more poor mental health days each month than male participants.


--
This suggests that other factors aside from sleep quality may contribute to the number of poor mental health days participants experience each month, particularly for female participants.


---
# To do's

### Quiz

- Quiz 3 due Monday 5/27






