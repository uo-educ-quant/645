---
title: "Cleaning Data & Handling Missingness"
subtitle: "EDUC 645: General Linear Model II"
author: "TBD"
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{R, setup, include = F}
library(pacman)
p_load(here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, DiagrammeR)

i_am("slides/EDUC645_cleaning_missing.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 6.75,
  fig.width = 10.5,
  warning = F,
  message = F
)
opts_chunk$set(dev = "svg")
options(device = function(file, width, height) {
  svg(tempfile(), width = width, height = height)
})
options(knitr.table.format = "html")

```

# Roadmap

---
# Goals for the unit
- Forms of Missingness
- Missing Data Handling Techniques
  - Traditional
  - Modern (mainly multiple imputation)
- Best Practices
 - Imputation
 - Reporting

---

# Problems with missing data (missingness)

Power: Missingness often reduces the number of useful observations, and therefore reduces power

--

Bias: Missingness induces bias as incomplete data…
- May not be Representative of the intended population
- May not be Balanced across observed and/or unobserved confounders as originally planned
- Are likely to have biased characteristics

--

Recoverability: Traditional approaches to missingness have limited our ability to recover statistical power and true variability

---
# Missing data mechanisms

Missing Completely at Random (MCAR): Missingness is unrelated to the values of variables in the data
Example: Missingness on Depression Scores (DV) because a school event attended by younger students prevented data collection from those students

--

Missing at Random (MAR): Missingness is related to values in the data, but can be explained by other (observed) values in the data
Generally (assumed to be) the most common form of missingness
Example: Missingness on Depression Scores (DV) due to perceived stigma of mental health concerns, but Depression Score may be predicted by age, victimization level, etc.

--

Missing Not at Random (MNAR): Missingness is caused by an individual’s value of the variable
Example: Missingness on BDI because of depression level (IV)

--

*All forms of missingness can co-occur among same data*

---
# Traditional methods for treating missingness
## and their shortcomings

Listwise or case deletion (avoid using): Delete observations with missingness
Under MCAR, reduces power; under MAR and MNAR, reduces power and induced bias
Particularly impactful in multivariate analysis: limited but widely dispersed missingness can lead to extensive case deletion

### Single Imputation Methods
- Mean substitution (never use): Replace missing values on a variable with average of that variable (artificially lowers variance, reduces power, and distorts covariances and intercorrelations among variables)
  The following can perform well, but modern methods perform better
- Averaging over missing items (artificially inflates variance of average value)
- Hot-decking: Replaces missing values with random observed values
- Last-observation-carried-forward 9 (reduces variability)

---
# Imputation

Uses the underlying structure of the data to replace missing values with new values that could have been reasonably obtained, had they not been missing
Aims to re-establish the relationship of the data with the population it was sampled from, without creating artificially precise data for the analysis

---
# Two modern approaches to imputation
## Different theoretical orientations to missingness

Full-Information Maximum-Likelihood (FIML) imputation
Estimate model parameters close to their values as estimated from complete data 
Model-specific and limited to models that are estimated using maximum-likelihood estimation (e.g., SEM, mixed/multilevel models, mixture models)
Multiple Imputation (MI) 
Aims to estimate complete data 
Not model-specific and therefore more versatile application to data analysis

---
# MI by Chained Equations (MICE)

- Chained equations: 
  - Focuses the algorithm on one variable at a time
  - Once variable is imputed, the algorithm moves to the next variable, skipping over complete variables, until all missing data is imputed
  - Process is repeated to create each imputed data set
- Numerous algorithms exist
  - Selection on variable being imputed (e.g., continuous, ordered, nominal/categorical)

Recommended R package: mice (https://amices.org/mice/)

???
- Chained equations approach focuses the algorithm on one variable at a time
- Once that variable is imputed, the algorithm moves to the next variable, skipping over complete variables, until all missing data is imputed – this process is then repeated many times to create each imputed data set
- Numerous algorithms exist, and selection depends mainly on the type of variable being imputed (e.g., continuous, ordered or un-ordered nominal/categorical, etc.)

---
# Multiple Imputation Process

```{r, echo=F, message=F, warning=F, fig.align="center", fig.height=7, fig.width=7}
m <- DiagrammeR::mermaid("
                         graph LR
                         A((d))-->B((m<sub>1</sub>))
                         A((d))-->C((m<sub>2</sub>))
                         A((d))-->D((m<sub>3</sub>))
                         B((m<sub>1</sub>))-->E((a<sub>1</sub>)) 
                         C((m<sub>2</sub>))-->F((a<sub>2</sub>)) 
                         D((m<sub>3</sub>))-->G((a<sub>3</sub>))
                         E((a<sub>1</sub>))-->H((r))
                         F((a<sub>2</sub>))-->H((r)) 
                         G((a<sub>3</sub>))-->H((r))
                         ")

widgetframe::frameableWidget(m)
```

Benefits of repeating the process, merging (averaging) each estimate of the missing data:
Produces a more accurate (and plausible) values
More precisely defines uncertainty in the data
Accounts for uncertainty from original data generation (measurement error) and of the imputation process

---
# Missing Data Diagnostics
## Inspect missing and imputed data before and after imputation

Before imputation
Calculate overall amount of missingness in the data (n, percent or proportion)
Inspect missingness (aka margin) plots, show the observed and missing values across two variables
Remember: Missingness mechanisms can differ between different variables
After imputation
Inspect strip plots, show the observed and imputed data together (as points), to identify erratic patterns among imputed data
Inspect kernel density plots, show the distributions of observed and imputed data rather than individual values as points (similar purpose to strip plots)

---
# Best Practices for Reporting

Always report the percent/proportion of data missing on variables included in analyses
Indicate the primary missingness mechanism you assume to be present, and provide a brief justification for why you make that assumption
Report the imputation method (MI or FIML), and if MI was used, report the number of imputed data sets (e.g., 20). Mention algorithm choice If space allows.
Cite the software/package used to impute data
In cases of substantial missingness, present (or at least mention) a sensitivity analysis of your primary analyses (that used imputed data) and complete case analyses

---
class: middle, inverse
# Synthesis and wrap-up
