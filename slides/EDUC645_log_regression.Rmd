---
title: "Logistic Regression"
subtitle: "EDUC 645: General Linear Model II"
author: "TBD"
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{R, setup, include = F}
library(pacman)
p_load(here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, lfe, arsenal, ggpubr, stargazer, fixest, gtsummary, huxtable)

i_am("slides/EDUC645_log_regression.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")


```

# Roadmap

---
# Goals for the unit
	• linear probability model and discuss the limitations
	• Understand the different model assumptions of logistic regression vs. linear regression.
	• concept of probability, odds, and logit (Distinguish between odds and probability.)
	• logistic function and the logistic regression model 
		○ continuous predictors
			§ how to interpret the model parameters, 
			§ inference for model parameters
		○ categorical predictors 
			§ how to interpret the model parameters, 
			§ inference for model parameters
		○ interaction between a continuous and categorical predictor, 
			§ how to interpret the model parameters, 
			§ inference for model parameters
	• glm function in R to fit the logistic regression model
• Discuss the predictive power, model fit, and diagnostics for a logistic regression model
	• Evaluate models based on Area Under ROC Curve method.
• probit and differentiate from logit

---
# Motivating Example: Logistic Regression

Meta Krüger's (1994) 
Study investigating gender differences in school leadership in Netherlands. 

The study implemented a matching procedure to generate pairs of comparable schools (N=98) with the only difference being that one school principal was female and the other male, then surveyed the school principals, teachers, and students. Due to deletion of incomplete observations, our dataset is a bit smaller than the one used in the article, it contains 94 school principals and 800 students.

```{r, echo = F}
principal <- rio::import(here::here("data", "principal.csv")) %>%
  mutate(attention = (q1+q2+q3)/3,
         affective = ifelse(q4 >= 3, 1, 0)) %>% 
  select(schid, stuid, female, stufemale, match, attention, affective) %>% 
  group_by(schid) %>% 
  mutate(attention = (attention-mean(attention))/sd(attention)) %>% 
  ungroup() 

head(principal)
```

---
# The Variables
 - schid, school identification number
 - stuid, student identification number within each school
 - pfemale, coded one for female principals and zero for male principals
 - sfemale, coded one for female students and zero for male students
 - match, coded one if student and principal are the same gender
 - q1, students' rating on a survey item, "Sometimes the principal talks to me", on a 4-point likert scale, 1=low, 4=high
 - q2, students' rating on a survey item, "I think the principal knows who I am", on a 4-point likert scale, 1=low, 4=high
 - q3, students' rating on a survey item, "Principal knows how well I am doing", on a 4-point likert scale, 1=low, 4=high
 - q4, students' rating on a survey item, "The principal is nice", on a 4-point likert scale, 1=low, 4=high

---
For starters, some data management; we're interested in the association between student-perceived attention from principal and affective attitude toward principal, therefore we compute two variables of interest:

 - attention: take the average score of attention items, q1, q2, and q3, then standardize it at school level to measure student-perceived attention
 - affective: recode q4 to be a binary variable coded one for students who rated 3 or 4 on this question ("the school principal is nice")
 
---
# Visualizing the relationship
 
Plot outcome variable, affective, on predictor variable, attention. What patterns do you notice from the plots?

```{r echo = FALSE, message = FALSE}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(color = "royalblue") +
  labs(y = "Affective attitude towards principal",
       x = "Attention from principal")
```

---
# Modeling the relationship

How to model these relationships in our analysis?

Our inquiry: The associations between student self-perceived attention from principal and affective attitude towards principal.

# show students what this would look like were one to estimate this relationship using OLS

What models should we use to fit the data when our outcome variable is a dichotomous variable?

---
# Logistic Regression

Binary (0 or 1) response (Y) and a single continuous predictor (X).

### Model for logistic regression with binary or binomial responses:

$$\log(\frac{p_i}{1-p_i})=\beta_0+\beta_1 x_i$$

where the observed values $Y_i \sim$ binomial with $p=p_i$ for a given $x_i$ and $n=1$ for binary responses.

???

The solid line is a linear regression fit with least squares to model the probability of a success (Y=1) for a given value of X.  With a binary response, the line doesn't fit the data well, and it produces predicted probabilities below 0 and above 1.  On the other hand, the logistic regression fit (dashed curve) with its typical "S" shape follows the data closely and always produces predicted probabilities between 0 and 1.  For these and several other reasons detailed in this chapter, we will focus on the following model for logistic regression with binary or binomial responses:

---

o	show plots of the residuals, residual v. fitted plot, etc. to build intuition around some of emergent issues with using OLS
  •	highlight that different approaches have different strengths/weaknesses:
o	In instances where the goal is to estimate treatment effects, and the predicted probability does not fall close to 0/1, an LPM approach is probably superior (more consistent and easier to interpret)
o	Estimates from logistic models with covariates are not comparable at different values of the covariates or across models
o	Highlight more clearly that LPM generate predicted values for some value of the predictor exceeding 0/1

---
# Binary Data

- You've learned to model continuous outcomes with linear regression models BUT there are many instances when we are interested in the probability of an outcome. How do we handle these sort of data?

--

- What about when you are interested in probability, an outcome related to binary data? (e.g., yes/no)  
    • Ex. probability of group given individual traits, probability of needs, etc.
    
--

- How are they different? Why can't we apply the same method?

---
# Binary Outcomes
- Outcomes with a yes/no or 0/1 response

--

- Examples:  
  - Depression or not?  
  - Vaccinated or not?  

--
	
- Proportion vs. Odds

---
# Proportion
- Description 1:

---
# Odds

Odds of an event: the probability of 'yes' divided by the probability of 'no'
$$Odds = \frac{p}{1(1-p)}$$

--

What are the odds of getting Tails when tossing a fair coin?

--

What are the odds of getting a 6 when tossing a fair dice?

---
# Odds and Probability

As the probability of an event increases, so do the odds

[insert data visualization comparing trajectories]

???
- As the probability of an event increases, so do the odds
- Odds increase *almost* exponentially as the probability increases

---
# Binary Outcome and Binary Predictor
- Measures of Association
	• Difference in probabilities = p1-p2
			- If difference in probabilities of the outcome across the categories is NOT 0, then predictor is associated with the outcome

--

	• Odds ratio (OR) = odds on category of predictor/odds other category of predictor
			- If OR is NOT 1, then predictor is associated with the outcome

???
- If the difference in probabilities of the outcome across the categories is NOT 0, there is an association between the outcome and the predictor

- If the OR is NOT 1, then there is an association between the predictor and the outcome

---
# Odds

- One way to quantify a XX's performance. 
Example 

__odds ratio__ \index{odds ratio} (OR): 

which tells us that the *odds* of a successful penalty kick are 3.05 times higher when the shooter's team is leading.

In general, we now have several ways of finding the odds of success under certain circumstances:

$$Odds = \frac{\# \textrm{successes}}{\# \textrm{failures}}=
\frac{\# \textrm{successes}/n}{\# \textrm{failures}/n}=
\frac{p}{1-p}$$

???

In our example, it is also possible to estimate the probability of a goal, $p$, for either circumstance. When the goalkeeper's team is behind, the probability of a successful penalty kick is $p$ = 22/24 or 0.833. We can see that the ratio of the probability of a goal scored divided by the probability of no goal is $(22/24)/(2/24)=22/2$ or 11, the odds we had calculated above. The same calculation can be made when the goalkeeper's team is not behind.
---

class: middle, inverse

# GLM and Logistic Regression

---
# Generalized linear models (GLMs)
- are a way in which to model a variety of different types of responses.
- we apply the general results of GLMs to the specific application of binomial responses. 

$Y$ = the number scored out of $n$ penalty kicks. 
The parameter, $p$, is the probability of a score on a single penalty kick. 

Recall that the theory of GLMs is based on the unifying notion of the one-parameter exponential family form:


$$f(y;\theta)=e^{[a(y)b(\theta)+c(\theta)+d(y)]}$$
---
# Binomial distribution and the Generalized Linear Model (GLM)

How can we apply the general approach of GLMs to binomial responses?
- We first write an expression for the probability of a binomial response 
  - Then use a little algebra to rewrite it until we can demonstrate that it, too, can be written in one-parameter exponential family form with $\theta = p$
  - Provide a way in which to specify the (canonical) link and the form for the model
  - Additional theory allows us to deduce the mean, standard deviation, and more

--

If $Y$ follows a binomial distribution with $n$ trials and probability of success $p$:

$$P(Y=y) = \binom{n}{y}p^y(1-p)^{(n-y)} \\
      =e^{y\log(p) + (n-y)\log(1-p) + \log\binom{n}{y}}$$
      
---
•	Explicit that the logit function serves as a link between linear regression and logistic regression
    o	directly connect these models parameter by parameter

---
# Binomial distribution and the GLM

*However*, this probability mass function is not quite in one-parameter exponential family form. 
- Note: there are two terms in the exponent which consist of a product of functions of $y$ and $p$. So more simplification is in order:

$$P(Y=y) = e^{y\log\left(\frac{p}{1-p}\right) + n\log(1-p)+ \log\binom{n}{y}}$$

- The one-parameter exponential family form for binomial responses shows that the canonical link is $\log(\frac{p}{1-p})$. 
- GLM theory suggests that constructing a model using the logit, the log odds of a score, as a linear function of covariates is a reasonable approach.   

---
# Likelihood Models and Estimation

Fitting simple linear models using ordinary least squares (OLS) assumes that the mean value of a response, Y, is linearly related to some variable, X. However, often responses are not normally distributed. 

*binary response linearly represented*
```{r}

```


---
# Fitting logistic regression requires *likelihood methods*. 

*Likelihood* function tells us how likely we are to observe our data for a given parameter value, pB. 
- Likelihood methods come into play is when data is produced from a complex structure which may imply correlation among outcomes (e.g., students' test scores taught by the same teacher)
- provide flexibility in the types of models we can fit
- provide ways in which to compare models

For a single X which has a Y, GBB, the likelihood function looks like:
[insert function]

*Distribution of likelihood function pB*
```{r, echo= F}
set.seed(110951)
x <- rgamma(1000, 6, 0.5)
library(MASS)
truehist(x, xlim = c(0, 35))
xpts <- seq(from = 0, to = 35, length = 1000)
lines(xpts, dgamma(xpts, 6, 0.5))
```

Note: we will not discuss MLE in the general form. Instead, we will consider a simple case of MLE that is relevant to the logistic regression.

---
# Maximum Likelihood Estimation

*Maximum likelihood estimation (MLE)* is a general class of method in statistics that is used to estimate the model parameters

[simple MLE estimation figure]
```{r}

```


---
# Maximum Likelihood Estimation

MLE: is the optimal estimate of pB, the value where we are most likely to see our data from all possible values between 0 and 1.
-  iterates over local maxima find the value of pB where the likelihood or log likelihood is a maximum.

*Contour plot*
```{r, echo = F}
# Reference: https://rpubs.com/gill1109/contour
fit <- fitdistr(x, "gamma")

NxPts <- 100
NyPts <- 100

xGridPts <- seq(from = 5, to = 7, length = NxPts)
yGridPts <- seq(from = 0.4, to = 0.6, length = NyPts)

xypairs <- expand.grid(xGridPts, yGridPts) 
       # coordinates of all gridpoints, rows of an N x 2 matrix
       # N = NxPts * NyPts

LogLikFun <- function(shape, rate) sum(dgamma(x, shape = shape, rate = rate, log = TRUE))

LogLikOnGrid <- mapply(LogLikFun, xypairs[ , 1], xypairs[ ,2]) # another long vector

## Can you understand the error message when you do
##    LogLikOnGrid <- outer(xGridPts, yGridPts, LogLikFun)   ?
## Why doesn't "outer" work here??
## Can you come up with something better than my solution?
## You'll also notice that "mapply" is rather slow ...
## There is an explicit "for loop" going on inside of "mapply".
## There ought to be a "vectorised" way to do this.

dim(LogLikOnGrid) <- c(NxPts, NyPts) # convert to matrix

## I'll subtract the maximum from the log likelihood function.
## We are only interested in *differences*, not in its absolute
## value. Now I know the maximum of the surface is at height z = 0.
## Also I reshape as a matrix.

MaxLogLik <- max(LogLikOnGrid)

LogLikOnGrid <- matrix(LogLikOnGrid, NxPts, NyPts) - max(LogLikOnGrid)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid, 
        levels = c( (0:-8)*10), col = "blue", add = TRUE)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid, 
        levels = - qchisq(0.95, 2)/2, col = "red", add = TRUE)
```

---
# Same idea, different plot

*Wire-frame plot*
```{r, echo = F}
persp(x = xGridPts, y = yGridPts, z = LogLikOnGrid)
```
---
# MLE limitations

MLE is primarily used as a point estimate solution and the information contained in a single value will always be limited. Likelihoods will not necessarily be symmetrically dispersed around the point of maximum likelihood. 

We may be interested in the full distribution of credible parameter values, so that we can perform sensitivity analyses and understand the possible outcomes or optimal decisions associated with particular credible intervals. 

Bayesian methods can be applied to circumvent these limitations.

---
# Assumptions
- Outcome (Y) is discrete binomial variable (0/1 variable)
- Must be enough responses in every category
- Linearity in the logit scale 
  - X's must be linearly related to logit(Y)
- Absence of multicollinearity
- No outliers
- Independence of (X,Y)'s
  - No clustering of data into groups/contexts that would provide information about the values of other errors

---
# Describe dichotomous outcome variable

```{r}
principal %>% 
  mutate(affective = recode(affective, '1' = "Yes", '0' = "No")) %>%
  ggplot(aes(affective)) +
  geom_bar(fill = "royalblue", width = 0.5, alpha = 0.8) +
  labs(x = "Affective attitude towards principal",
       y = "Number of Students")
```

---
# Describe dichotomous outcome variable
Plot outcome variable, affective, on predictor variable, attention:

```{r}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(color = "royalblue") +
  labs(y = "Affective attitude towards principal",
       x = "Attention from principal")
```

---
# Interpretation of Model Parameters

$$\ln(\frac{p_i}{1-p_i})=\beta_0+\beta_1 X_i$$

$\beta_1$: Change in log odds for 1 unit change in $X_i$

[insert example]
---

# Linear probability model (LPM)
Back to our example
```{r}
m1 <- lm(affective ~ attention, principal)
summary(m1)
```

Does the regression coefficient of attention confirm your previous impression with the plot?

---

Visualize the coefficient/slope of the fitted line (basically, we force the relationship to be linear):

```{r}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(alpha = 0.01) +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") + 
  labs(y = "Affective attitude towards principal",
       x = "Self-perceived attention from principal")
```


Interpret the results (report regression coefficients **on a probability scale**) and the figure. 

Will this be the model where you stop at?

---

#### Binomial logistic regression

```{r}
m2 <- lm(affective ~ attention + match, principal)

m3 <- glm(affective ~ attention, principal, 
          family = binomial(link = "logit"))

m4 <- glm(affective ~ attention + match, principal,
          family = binomial(link = "logit"))

summary(m3)
```

---
# Visualize the coefficient on a log-odds scale

Model the change in log-odds of affective in a linear function of attention:

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = .)) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (LOG-ODDS)",
       x = "Self-perceived attention from principal")
```

---
# Coefficient on a probability scale (mapping the parameters to probability nonlinearly)

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```

???

Note: in the data, "attention" ranges from -2.42 to 2.61, the plot is therefore limited to a fraction when the probability of "affective" approaching one but still below 0.5. Because we cannot easily guess the missing plot fraction (as appose to when the line is linear, we can tell where the line goes simply by looking at the slope), this plot is not telling us enough information about the population of interest:

---

Manipulate the X axis to show the nonlinear relationship in its full image:

```{r}
tibble(attention = (-15):20) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```

Interpret the results (report regression coefficients **on a log-odds scale**) and the two figures.


---
# Interpretation of Model Parameters
To get the odds ratio, we need to back transform and exponentiate the coefficient, $\beta_i$:

$$\beta_1 = ln(\frac{odds|X=1}{odds|X=0})$$
   $$= ln(OR_{X=1:X=0})$$

$$OR = e^{ln(OR_{X=1:X=0})}$$
  $$= e^{\beta_1}$$

---

•	Give students opportunities to practice calculating odds ratios by hand, and the interpreting them

---
# Logistic Regression Assumptions

Linearity assumption: the linear relationship between continuous predictor variable and the logit of the outcome variable
2. Binomial logistic regression (logistic regression/logit model)

```{r}
m3 <- glm(affective ~ attention, principal, 
          family = binomial(link = "logit"))
m4 <- glm(affective ~ attention + match, principal,
          family = binomial(link = "logit"))
```

Check for critical ASSUMPTIONS that unique to logistic regression:

 - linearity assumption/the linear relationship between continuous predictor variable and the logit of the outcome variable

```{r}
probabilities <- predict(m3, type = "response")

#principal %>% 
#  mutate(logit_affective = log(probabilities/(1-probabilities))) %>% 
#      ggplot(aes(attention, logit_affective)) + 
#      geom_point (alpha = 0.5) +
#      geom_smooth(method = "loess", color = "brown") 

```

---
# Outliers: Cook's distance plot 
 
```{r}
plot(m3, which = 4, id.n = 3)
```

---
# Outliers: Residual Errors 

Check standardized residual errors to identify outliers 
Rule of thumb: data points with an absolute error above 3

```{r}
principal_checked <- broom::augment(m3) %>% 
  mutate(index = 1:n())

principal_checked %>% top_n(3, .cooksd)

principal_checked %>% 
  mutate(affective = as.factor(affective)) %>% 
  ggplot(aes(index, .std.resid)) +
  geom_point(aes(color = affective))
```

---
# Multicollinearity  

can add another predictor to see if there is collinearity existing (variance inflation factor exceeds 5) - we're good

```{r}
car::vif(m4)
```

---
# Multicollinearity  
The logit models are usually estimated by a maximum likelihood estimator/MLE.

```{r}
summary(m3)
summary(m4)
```

---
# Visualize the coefficient on a **log-odds** scale 
### Model the change in log-odds of affective in a linear function of attention

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = .)) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (LOG-ODDS)",
       x = "Attention from principal")
```

---
# Visualize the coefficient on a *probability* scale 
### Mapping the parameters to probability nonlinearly

```{r}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```

???

Coder note: in the data, "attention" ranges from -2.42 to 2.61, the plot is therefore limited to a fraction when the probability of "affective" approaching one but still below 0.5. Because we cannot easily guess the missing plot fraction (as appose to when the line is linear, we can tell where the line goes simply by looking at the slope), this plot is not telling us enough information about the population of interest:

---

Manipulated X axis to show the nonlinear relationship in its full image:

```{r}
tibble(attention = (-3):15) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```


---
# Interpret the results

report regression coefficients **on a log-odds scale**

```{r}
tibble(attention = (-15):20) %>% 
  mutate(pred = predict(m3, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```

---
# Comparing models 

Putting models together and report them in a table:

```{r}
huxtable::huxreg(
  "LPM" = m1, 
  "LPM" = m2,
  "Logistic" = m3,
  "Logistic" = m4,
  coefs = c("Attention" = "attention",
            "Matched gender" = "match")
)
```

---
class: middle, inverse

# Interactions

---
# Assess Interactions

- Assess effect modification by adding interaction term to the model

Model *without* interaction term:

$$ln({Y_{odds}}) - {\beta_0} + {\beta_1}X_1 + {\beta_2}X_2$$
Model *with* interaction term:
$$ln({Y_{odds}}) = {\beta_0} + {\beta_1}X_1 + {\beta_2}X_2 + {\beta_3}(X_1*X_2)$$
---
# Interaction - categorical X categorical

---
# Interaction - continous X categorical

[Assess Interactions - example walkthrough]

---
# Interactions - centering variable

---
# Interaction - continous X continuous
[Assess Interactions - example walkthrough]

[interpretation of output, example write up]

---
# Tests for Significance of Model Coefficients

---
# Confidence Intervals for Model Coefficients


---
class: middle, inverse

# Diagnostics

---
# Testing for Goodness-of-Fit

---
# Assess Confounding
1. Compare the unadjusted regression coefficients to the adjusted regression coefficients (not the ORs) 
- Calculating change in coefficient:
$$100*\frac{\beta_{adjusted} - \beta_{unadjusted}} {\beta_{unadjusted}}$$
2. If the change in coefficients > 10%, there is evidence for confounding by the variable in the adjusted model (aka, 10% confounding rule)

---

# Influential Observations

- Are there observations that greatly change the estimated regression coefficients if they are removed from the dataset?
- Same concept as with DFBetas from multiple linear regression

---
# Influential Observations

[insert Leverage plot]

---

# Predicted Values: Probabilities
- Coefficients tell us the *average* predicted probability for a person, but what if we want to know about more specific groups or contexts?

--

- Obtain predicted probabilities for each person depending on their characteristics

$$p = \frac{e^{(\beta_0 + \beta_1X)}}{1 + e^{{(\beta_0 + \beta_1X)}}}$$
---
class: middle, inverse

# Assessing Predicted Values
 
---

# Assessing Predicted Values

* In MLR, $R^2$ indicates good prediction

--

* In logistic regression, use the *predicted probabilities* 
  - *predicted probabilities* classify people according to one of the two groups of the predictor variable.

---

# Classification Rule
* Need a threshold for defining probability for belonging in one or two of the groups

* But how do we determine an appropriate threshold?

--

* Calculate a cut-off by examining the *sensitivity* and *specificity* of our model

---
# Types of Classification

|             |         |Predicted|       |
|-------------|---------|---------|-------|
|             |         |*Y = 1*  |*Y = 0*|
|**Observed** | *Y = 1* | True +  | False-|
|             | *Y = 0* | False + | True- |

### Sensitivity
* What is the ratio of correct positive predictions (Y = 1) to total positive predictions?
_Positive predictive value (PPV)_ = $\frac{number of True +} {Total_{observed} Y = 1}$

### Specificity
* What is the ratio of correct negative predictions (Y = 0) to total negative predictions?
* _Negative predictive value (NPV)_ = $\frac{number of True -} {Total_{observed} Y = 0}$

---
# Specificity vs. Sensitivity
[insert hypothetical figure 
"Specificity and Sensitivity Change as the Probability Cutoff Changes"]

---
class: center, inverse

# Receiver Operating Characteristic (ROC) Curve

---
# ROC Curve: Gauging Accuracy of Model
* Plot of true positive rate against the false positive rate for the different possible cutoff points of a diagnostic test
* Illustrates the trade off between *sensitivity* and *specificity*
  - Increase in *sensitivity* will result in decrease in *specificity*, and vice versa
* The __area under the curve (AUC)__ measures *accuracy*
  - More accurate tests, the curve is closer to the left-hand border and the top border of the ROC

---
# Area Under the (ROC) Curve

```{r}
simple_roc <- function(labels, scores){
  labels <- labels[order(scores, decreasing=TRUE)]
  data.frame(TPR=cumsum(labels)/sum(labels), FPR=cumsum(!labels)/sum(!labels), labels)
}

set.seed(1)
sim_d <- function(N, noise=100){
  x <- runif(N, min=0, max=100)
  y <- 122 - x/2 + rnorm(N, sd=noise)
  dv <- factor(y > 100)
  data.frame(x, y, dv)
}
dv_d <- sim_d(500, 10)

test_set_idx <- sample(1:nrow(dv_d), size=floor(nrow(dv_d)/4))

test_set <- dv_d[test_set_idx,]
training_set <- dv_d[-test_set_idx,]
```


```{r}
test_set %>% 
  ggplot(aes(x=x, y=y, col=dv)) + 
  scale_color_manual(values=c("blue", "orange")) + 
  geom_point() + 
  ggtitle("DV to X")
```

---
# Examining the ROC curve

* Two classifiers that put the labels in the same order will have exactly the same ROC curve regardless of the absolute values of the scores.

* This is shown by comparing the ROC curve you get using either the ‘response’ or the ‘link’ predictions from a logistic regression model. 

* The ‘response’ scores have been mapped into the range between 0 and 1 by a sigmoid function and the ‘link’ scores have not.

```{r, echo = T}
fit_glm <- glm(dv ~ x, training_set, family=binomial(link="logit"))

glm_link_scores <- predict(fit_glm, test_set, type="link")

glm_response_scores <- predict(fit_glm, test_set, type="response")

score_data <- data.frame(link=glm_link_scores, 
                         response=glm_response_scores,
                         dv=test_set$dv,
                         stringsAsFactors=FALSE)
```

---
# Examining the ROC Curve

```{r plot-first, echo = FALSE, fig.cap="add caption"}
score_data %>% 
  ggplot(aes(x=link, y=response, col=dv)) + 
  scale_color_manual(values=c("black", "red")) + 
  geom_point() + 
  geom_rug() + 
  ggtitle("Both link and response scores put cases in the same order")
```

---
# Plotting the ROC Curve

```{r plot-second, echo = FALSE}
library(pROC)
plot(roc(test_set$dv, glm_response_scores, direction="<"),
     col="yellow", lwd=3, main="The turtle finds its way")
## 
## Call:
## roc.default(response = test_set$bad_widget, predictor = glm_response_scores,     direction = "<")
## 
## Data: glm_response_scores in 59 controls (test_set$bad_widget FALSE) < 66 cases (test_set$bad_widget TRUE)
## Area under the curve: 0.9037
glm_simple_roc <- simple_roc(test_set$dv=="TRUE", glm_link_scores)
with(glm_simple_roc, points(1 - FPR, TPR, col=1 + labels))
```

---
# Obtaining the AUC

.pull-left[
```{r plot-third, echo = FALSE}
set.seed(1)
N <- 2000
P <- 0.01
rare_success <- sample(c(TRUE, FALSE), N, replace=TRUE, prob=c(P, 1-P))
guess_not <- rep(0, N)
plot(roc(rare_success, guess_not), print.auc=TRUE)

## Call:
## roc.default(response = rare_success, predictor = guess_not)
## 
## Data: guess_not in 1978 controls (rare_success FALSE) < 22 cases (rare_success TRUE).
## Area under the curve: 0.5

simp_roc <- simple_roc(rare_success, guess_not)
with(simp_roc, lines(1 - FPR, TPR, col="blue", lty=2))
```
]

.pull-right[
```{r ref.label = 'plot-third', fig.show = 'hide'}
```
]

---

### AUC Guidelines:
* Will vary depending on the outcome variable, but here are some general guidelines:
  - AUC = 0.5 = Poor (equal to random chance)
  - 0.7 < AUC < 0.8 = Acceptable
  - 0.8 < AUC < 0.9 = Excellent
  - AUC > .9 = Outstanding

---

[shiny app for playing around with ROC and AUC:
https://kennis-research.shinyapps.io/ROC-Curves/]


---
# Binomial and Beyond
- Probit regression
- Multinomial logistic regression
- Ordinal regression
- Count data
- Hazard ratio
- Survival analysis

---
class: middle, inverse
# Synthesis and wrap-up

---
# Logistic vs. OLS regression
|                 | Linear Least Squares | Binomial Regression |
|-----------------|----------------------|---------------------|
|Response variable| Normal distribution  | Number of successes in $n$ trials |
|Variance         | equal for each level of X | np(1−p) for each level of X |
|Model fitting    | μ=β0+β1x using Least Squares | log(p1−p)=β0+β1x using Maximum Likelihood |
|EDA              | plot X vs. Y; add line | find log⁡(odds) for several subgroups; plot vs. X|
|Comparing models | extra sum of squares F-tests; AIC/BIC | drop-in-deviance tests; AIC/BIC |
|Interpreting coef| β1= change in mean response for unit change in X | eβ1= percent change in odds for unit change in X|