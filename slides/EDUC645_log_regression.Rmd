---
title: "Logistic Regression"
subtitle: "EDUC 645: General Linear Model II"
author: "TBD"
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{R, setup, include = F}
library(pacman)
p_load(here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, lfe, arsenal, ggpubr, stargazer, fixest, gtsummary, huxtable)

i_am("slides/EDUC645_log_regression.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 6.75,
  fig.width = 10.5,
  warning = F,
  message = F
)

```

# Roadmap

---
# Goals for the unit
	• linear probability model and discuss the limitations
	• Understand the different model assumptions of logistic regression vs. linear regression.
	• concept of probability, odds, and logit (Distinguish between odds and probability.)
	• logistic function and the logistic regression model 
		○ continuous predictors
			§ how to interpret the model parameters, 
			§ inference for model parameters
		○ categorical predictors 
			§ how to interpret the model parameters, 
			§ inference for model parameters
		○ interaction between a continuous and categorical predictor, 
			§ how to interpret the model parameters, 
			§ inference for model parameters
	• glm function in R to fit the logistic regression model
• Discuss the predictive power, model fit, and diagnostics for a logistic regression model
	• Evaluate models based on Area Under ROC Curve method.
• probit and differentiate from logit

---
# A Motivating Question

Study investigating gender differences in school leadership in Netherlands (Krüger, 1994 [insert article reference]). The study matched comparable schools (N=98) then surveyed the school principals, teachers, and students. 

We're interested in the association between school-level student-perceived *attention from principal* and *affective attitude toward principal*.

---

# Reviewing the data

```{r, echo = F}
principal <- rio::import(here::here("data", "principal.csv")) %>%
  mutate(attention = (q1+q2+q3)/3,
         affective = ifelse(q4 >= 3, 1, 0)) %>% 
  select(schid, stuid, female, stufemale, match, attention, affective) %>% 
  group_by(schid) %>% 
  mutate(attention = (attention-mean(attention))/sd(attention)) %>% 
  ungroup() 

head(principal)
```

---
# Describe dichotomous outcome variable

```{r, echo = F}
principal %>% 
  mutate(affective = recode(affective, '1' = "Yes", '0' = "No")) %>%
  ggplot(aes(affective)) +
  geom_bar(fill = "royalblue", width = 0.5, alpha = 0.8) +
  labs(x = "Affective attitude towards principal",
       y = "Number of Students")
```

---
# Describe affective on attention

```{r, echo = F}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(color = "royalblue") +
  labs(y = "Affective attitude towards principal",
       x = "Attention from principal")
```

---
# Visualizing the relationship

Plot outcome variable, affective, on predictor variable, attention. What patterns do you notice from the plots?

```{r, echo = FALSE}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(color = "royalblue") +
  labs(y = "Affective attitude towards principal",
       x = "Attention from principal")
```

---
# Modeling the relationship

Previously you have practiced modeling outcome variables with continuous (Gaussian) distributions, with various kinds of predictor variables. 

Our inquiry: The association between students among school's attention from principal and attitude towards principal.

With the case of Krüger's data, we need to model the relationship between a dichotomous outcome variable in our analysis.

---
# Binary Data

- This is an instance many when we are interested in the probability of an outcome.
    • Ex. probability of group given individual traits, probability of needs, etc.

--

- How is this different from if attitude towards a principal was a continuous scale, rather than binary/dichotomous?

---

# Other Common Forms of Non-Linear Analysis

- Probit regression
- Multinomial logistic regression
- Ordinal logistic regression
- Hazard ratio
- Survival analysis

---

class: middle, inverse

# GLM and Logistic Regression

---

# Revisiting the Generalized Linear Model (GLM)
- A way in which to model a variety of different types of outcome variables

$Y$ = the number scored out of $n$ penalty kicks. 
The parameter, $p$, is the probability of a score on a single penalty kick. 

Recall that the theory of GLMs is based on the unifying notion of the one-parameter exponential family form:

$$f(y;\theta)=e^{[a(y)b(\theta)+c(\theta)+d(y)]}$$
---
# Binomial distribution and the Generalized Linear Model (GLM)

How can we apply the general approach of GLMs to binomial responses
- We first write an expression for the probability of a binomial response 
  - Then use a little algebra to rewrite it until we can demonstrate that it, too, can be written in one-parameter exponential family form with $\theta = p$
  - Provide a way in which to specify the (canonical) link and the form for the model

--

If $Y$ follows a binomial distribution with $n$ trials and probability of success $p$:

$$P(Y=y) = \binom{n}{y}p^y(1-p)^{(n-y)} \\
      =e^{y\log(p) + (n-y)\log(1-p) + \log\binom{n}{y}}$$
---
# Logistic Regression

Binary (0 or 1) response (Y) and a single continuous predictor (X).

### Model for logistic regression with binary or binomial responses:

$$\log(\frac{p_i}{1-p_i})=\beta_0+\beta_1 x_i$$

where the observed values $Y_i \sim$ binomial with $p=p_i$ for a given $x_i$ and $n=1$ for binary responses.

???

The solid line is a linear regression fit with least squares to model the probability of a success (Y=1) for a given value of X.  With a binary response, the line doesn't fit the data well, and it produces predicted probabilities below 0 and above 1.  On the other hand, the logistic regression fit (dashed curve) with its typical "S" shape follows the data closely and always produces predicted probabilities between 0 and 1.  For these and several other reasons detailed in this chapter, we will focus on the following model for logistic regression with binary or binomial responses:

•	Explicit that the logit function serves as a link between linear regression and logistic regression
    o	directly connect these models parameter by parameter

---
# Binomial distribution and the GLM: Linking the two

## The missing link
*However*, this probability mass function is not quite in one-parameter exponential family form. 
- Note: there are two terms in the exponent which consist of a product of functions of $y$ and $p$. So more simplification is in order:

$$P(Y=y) = e^{y\log\left(\frac{p}{1-p}\right) + n\log(1-p)+ \log\binom{n}{y}}$$

- The one-parameter exponential family form for binomial responses shows that the canonical link is $\log(\frac{p}{1-p})$. 
- GLM theory suggests that constructing a model using the logit, the log odds of a score, as a linear function of covariates is a reasonable approach.   

---
# Likelihood Models and Estimation

Fitting simple linear models using OLS assumes that the mean value of a response, $Y$, is linearly related to some variable, X. 

However, often responses are not normally distributed. 

*binary response linearly represented*
```{r}

```


---
# Fitting logistic regression requires *likelihood methods*. 

*Likelihood* function tells us how likely we are to observe our data for a given parameter value, pB. 
- come into play is when data is produced from a complex structure which may imply correlation among outcomes (e.g., students' test scores taught by the same teacher)
- provide flexibility in the types of models we can fit
- provide ways in which to compare models

For a single X which has a Y, GBB, the likelihood function looks like:
[insert function]

*Distribution of likelihood function pB*
```{r, echo= F}
set.seed(110951)
x <- rgamma(1000, 6, 0.5)
library(MASS)
truehist(x, xlim = c(0, 35))
xpts <- seq(from = 0, to = 35, length = 1000)
lines(xpts, dgamma(xpts, 6, 0.5))
```

Note: we will not discuss MLE in the general form. Instead, we will consider a simple case of MLE that is relevant to the logistic regression.

---
# Maximum Likelihood Estimation

*Maximum likelihood estimation (MLE)* is a general class of method in statistics that is used to estimate the model parameters

[simple MLE estimation figure]
```{r}

```

---
# Maximum Likelihood Estimation

MLE: is the optimal estimate of pB, the value where we are most likely to see our data from all possible values between 0 and 1.
-  iterates over local maxima find the value of pB where the likelihood or log likelihood is a maximum.

*Contour plot*
```{r, echo = F}
# Reference: https://rpubs.com/gill1109/contour
fit <- fitdistr(x, "gamma")

NxPts <- 100
NyPts <- 100

xGridPts <- seq(from = 5, to = 7, length = NxPts)
yGridPts <- seq(from = 0.4, to = 0.6, length = NyPts)

xypairs <- expand.grid(xGridPts, yGridPts) 
       # coordinates of all gridpoints, rows of an N x 2 matrix
       # N = NxPts * NyPts

LogLikFun <- function(shape, rate) sum(dgamma(x, shape = shape, rate = rate, log = TRUE))

LogLikOnGrid <- mapply(LogLikFun, xypairs[ , 1], xypairs[ ,2]) # another long vector

## Can you understand the error message when you do
##    LogLikOnGrid <- outer(xGridPts, yGridPts, LogLikFun)   ?
## Why doesn't "outer" work here??
## Can you come up with something better than my solution?
## You'll also notice that "mapply" is rather slow ...
## There is an explicit "for loop" going on inside of "mapply".
## There ought to be a "vectorised" way to do this.

dim(LogLikOnGrid) <- c(NxPts, NyPts) # convert to matrix

## I'll subtract the maximum from the log likelihood function.
## We are only interested in *differences*, not in its absolute
## value. Now I know the maximum of the surface is at height z = 0.
## Also I reshape as a matrix.

MaxLogLik <- max(LogLikOnGrid)

LogLikOnGrid <- matrix(LogLikOnGrid, NxPts, NyPts) - max(LogLikOnGrid)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid, 
        levels = c( (0:-8)*10), col = "blue", add = TRUE)

contour(x = xGridPts, y = yGridPts, z = LogLikOnGrid, 
        levels = - qchisq(0.95, 2)/2, col = "red", add = TRUE)
```

---
# Same idea, different plot

*Wire-frame plot*
```{r, echo = F}
persp(x = xGridPts, y = yGridPts, z = LogLikOnGrid)
```

---
# MLE limitations

- MLE is primarily a single point estimate solution and the information contained in a single value
- Likelihoods will not necessarily be symmetrically dispersed around the point of maximum likelihood. 
We may be interested in the full distribution of credible parameter values, so that we can perform sensitivity analyses and understand the possible outcomes or optimal decisions associated with particular credible intervals. 

Bayesian methods can be applied to circumvent these limitations.

---
# Interpretation of Model Parameters

$$\ln(\frac{p_i}{1-p_i})=\beta_0+\beta_1 X_i$$
$\beta_1$: Change in log odds for 1 unit change in $X_i$

[insert example]
---

# Linear probability model (LPM)
Back to our example
```{r}
m1 <- lm(affective ~ attention, principal)
summary(m1)
```

Does the regression coefficient of attention confirm your previous impression with the plot?

---

Visualize the coefficient/slope of the fitted line (basically, we force the relationship to be linear):

```{r, echo = F}
principal %>% 
  ggplot(aes(attention, affective)) +
  geom_point(alpha = 0.01) +
  geom_smooth(method = "lm", se = FALSE, color = "royalblue") + 
  labs(y = "Affective attitude towards principal",
       x = "Self-perceived attention from principal")
```


Interpret the results (report regression coefficients **on a probability scale**) and the figure. 

---
# Visualize the coefficient on a log-odds scale

Model the change in log-odds of affective in a linear function of attention:

```{r, echo = F}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m1, newdata = .)) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (LOG-ODDS)",
       x = "Self-perceived attention from principal")
```

---
# Coefficient on a probability scale (mapping the parameters to probability nonlinearly)

```{r, echo = F}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m1, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```

???

Note: in the data, "attention" ranges from -2.42 to 2.61, the plot is therefore limited to a fraction when the probability of "affective" approaching one but still below 0.5. Because we cannot easily guess the missing plot fraction (as appose to when the line is linear, we can tell where the line goes simply by looking at the slope), this plot is not telling us enough information about the population of interest:

---

Manipulate the X axis to show the nonlinear relationship in its full image:

```{r, echo = F}
tibble(attention = (-15):20) %>% 
  mutate(pred = predict(m1, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "royalblue") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Self-perceived attention from principal")
```

Interpret the results (report regression coefficients **on a log-odds scale**) and the two figures.

---
# Visualize the coefficient on a **log-odds** scale 
### Model the change in log-odds of affective in a linear function of attention

```{r, echo = F}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m1, newdata = .)) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (LOG-ODDS)",
       x = "Attention from principal")
```

---
# Visualize the coefficient on a *probability* scale 
### Mapping the parameters to probability nonlinearly

```{r, echo = F}
tibble(attention = (-3):3) %>% 
  mutate(pred = predict(m1, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```

???

Coder note: in the data, "attention" ranges from -2.42 to 2.61, the plot is therefore limited to a fraction when the probability of "affective" approaching one but still below 0.5. Because we cannot easily guess the missing plot fraction (as appose to when the line is linear, we can tell where the line goes simply by looking at the slope), this plot is not telling us enough information about the population of interest:

---

Manipulated X axis to show the nonlinear relationship in its full image:

```{r, echo = F}
tibble(attention = (-3):15) %>% 
  mutate(pred = predict(m1, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```


---
# Interpret the results

report regression coefficients **on a log-odds scale**

```{r, echo = F}
tibble(attention = (-15):20) %>% 
  mutate(pred = predict(m1, newdata = ., type = "response")) %>% 
  ggplot(aes(attention, pred)) +
  geom_line(color = "brown") +
  labs(y = "Affective attitude towards principal (PROBABILITY)",
       x = "Attention from principal")
```

---
# Interpretation of Model Parameters

---
# Binary Outcomes
- Outcomes with a yes/no or 0/1 response

--

- Examples:  
  - Depression or not?  
  - Vaccinated or not?  

--
	
- Proportion vs. Odds

---
# Proportion
- Description 1:

---
# Odds

Odds of an event: the probability of 'yes' divided by the probability of 'no'
$$Odds = \frac{p}{1(1-p)}$$

--

What are the odds of getting Tails when tossing a fair coin?

--

What are the odds of getting a 6 when tossing a fair dice?

---
# Odds and Probability

As the probability of an event increases, so do the odds

[insert data visualization comparing trajectories]

???
- As the probability of an event increases, so do the odds
- Odds increase *almost* exponentially as the probability increases

---
# Binary Outcome and Binary Predictor
- Measures of Association
	• Difference in probabilities = p1-p2
			- If difference in probabilities of the outcome across the categories is NOT 0, then predictor is associated with the outcome

--

	• Odds ratio (OR) = odds on category of predictor/odds other category of predictor
			- If OR is NOT 1, then predictor is associated with the outcome

???
- If the difference in probabilities of the outcome across the categories is NOT 0, there is an association between the outcome and the predictor

- If the OR is NOT 1, then there is an association between the predictor and the outcome

---
# Odds

- One way to quantify a XX's performance. 
Example 

__odds ratio__ \index{odds ratio} (OR): 

which tells us that the *odds* of a successful penalty kick are 3.05 times higher when the shooter's team is leading.

In general, we now have several ways of finding the odds of success under certain circumstances:

$$Odds = \frac{\# \textrm{successes}}{\# \textrm{failures}}=
\frac{\# \textrm{successes}/n}{\# \textrm{failures}/n}=
\frac{p}{1-p}$$

???

In our example, it is also possible to estimate the probability of a goal, $p$, for either circumstance. When the goalkeeper's team is behind, the probability of a successful penalty kick is $p$ = 22/24 or 0.833. We can see that the ratio of the probability of a goal scored divided by the probability of no goal is $(22/24)/(2/24)=22/2$ or 11, the odds we had calculated above. The same calculation can be made when the goalkeeper's team is not behind.

---


To get the odds ratio, we need to back transform and exponentiate the coefficient, $\beta_i$:

$$\beta_1 = ln(\frac{odds|X=1}{odds|X=0})$$
   $$= ln(OR_{X=1:X=0})$$

$$OR = e^{ln(OR_{X=1:X=0})}$$
  $$= e^{\beta_1}$$

---
# Practice calculating OR by hand

--

[insert interpretation]

---

```{r, echo = F}
probabilities <- predict(m1, type = "response")

principal %>% 
  mutate(logit_affective = log(probabilities/(1-probabilities))) %>% 
      ggplot(aes(attention, logit_affective)) + 
      geom_point (alpha = 0.5) +
      geom_smooth(method = "loess", color = "brown") 

```

---
# Assumptions
- Outcome (Y) is discrete binomial variable (0/1 variable)
- Must be enough responses in every category
- Linearity in the logit scale 
  - X's must be linearly related to logit(Y)
- Absence of multicollinearity
- No outliers
- Independence of (X,Y)'s
  - No clustering of data into groups/contexts that would provide information about the values of other errors

---
# Logistic Regression Assumptions

1. Linearity assumption: the linear relationship between continuous predictor variable and the logit of the outcome variable

2. Binomial logistic regression (logistic regression/logit model)

```{r}
m2 <- lm(affective ~ attention + match, principal)

m3 <- glm(affective ~ attention, principal, 
          family = binomial(link = "logit"))
m4 <- glm(affective ~ attention + match, principal,
          family = binomial(link = "logit"))
```

Check for critical ASSUMPTIONS that unique to logistic regression:

 - linearity assumption/the linear relationship between continuous predictor variable and the logit of the outcome variable

---
# Outliers: Cook's distance plot 
 
```{r}
plot(m3, which = 4, id.n = 3)
```

---
# Outliers: Residual Errors 

Check standardized residual errors to identify outliers 
Rule of thumb: data points with an absolute error above 3

```{r}
principal_checked <- broom::augment(m3) %>% 
  mutate(index = 1:n())

principal_checked %>% top_n(3, .cooksd)

principal_checked %>% 
  mutate(affective = as.factor(affective)) %>% 
  ggplot(aes(index, .std.resid)) +
  geom_point(aes(color = affective))
```

---
# Multicollinearity  

can add another predictor to see if there is collinearity existing (variance inflation factor exceeds 5) - we're good

```{r}
car::vif(m4)
```

---
# Multicollinearity  

```{r}
summary(m3)
summary(m4)
```


# Comparing models 

Putting models together and report them in a table:

```{r}
huxtable::huxreg(
  "LPM" = m1, 
  "LPM" = m2,
  "Logistic" = m3,
  "Logistic" = m4,
  coefs = c("Attention" = "attention",
            "Matched gender" = "match")
)
```

---
class: middle, inverse

# Interactions

---
# Assess Interactions

- Assess effect modification by adding interaction term to the model

Model *without* interaction term:

$$ln({Y_{odds}}) - {\beta_0} + {\beta_1}X_1 + {\beta_2}X_2$$
Model *with* interaction term:
$$ln({Y_{odds}}) = {\beta_0} + {\beta_1}X_1 + {\beta_2}X_2 + {\beta_3}(X_1*X_2)$$
---
# Interaction - categorical X categorical

---
# Interaction - continous X categorical

[Assess Interactions - example walkthrough]

---
# Interactions - centering variable

---
# Interaction - continous X continuous
[Assess Interactions - example walkthrough]

[interpretation of output, example write up]

---
# Tests for Significance of Model Coefficients

---
# Confidence Intervals for Model Coefficients

{NOTES FROM DL}
o	show plots of the residuals, residual v. fitted plot, etc. to build intuition around some of emergent issues with using OLS
  •	highlight that different approaches have different strengths/weaknesses:
o	In instances where the goal is to estimate treatment effects, and the predicted probability does not fall close to 0/1, an LPM approach is probably superior (more consistent and easier to interpret)
o	Estimates from logistic models with covariates are not comparable at different values of the covariates or across models
o	Highlight more clearly that LPM generate predicted values for some value of the predictor exceeding 0/1


---
class: middle, inverse

# Diagnostics, Predicted Values, and Limitations

---

# Testing for Goodness-of-Fit

---
# Assess Confounding
1. Compare the unadjusted regression coefficients to the adjusted regression coefficients (not the ORs) 
- Calculating change in coefficient:
$$100*\frac{\beta_{adjusted} - \beta_{unadjusted}} {\beta_{unadjusted}}$$
---

# Influential Observations

- Are there observations that greatly change the estimated regression coefficients if they are removed from the dataset?
- Same concept as with DFBetas from multiple linear regression

---
# Influential Observations

[insert Leverage plot]

---

# Predicted Values: Probabilities
- Coefficients tell us the *average* predicted probability for a person, but what if we want to know about more specific groups or contexts?

--

- Obtain predicted probabilities for each person depending on their characteristics

$$p = \frac{e^{(\beta_0 + \beta_1X)}}{1 + e^{{(\beta_0 + \beta_1X)}}}$$
---

# Assessing Predicted Values

* In MLR, $R^2$ indicates good prediction

--

* In logistic regression, use the *predicted probabilities* 
  - *predicted probabilities* classify people according to one of the two groups of the predictor variable.

---

# Classification Rule
* Need a threshold for defining probability for belonging in one or two of the groups

* But how do we determine an appropriate threshold?

--

* Calculate a cut-off by examining the *sensitivity* and *specificity* of our model

---
# Types of Classification

|             |         |Predicted|       |
|-------------|---------|---------|-------|
|             |         |*Y = 1*  |*Y = 0*|
|**Observed** | *Y = 1* | True +  | False-|
|             | *Y = 0* | False + | True- |

### Sensitivity
* What is the ratio of correct positive predictions (Y = 1) to total positive predictions?
_Positive predictive value (PPV)_ = $\frac{number of True +} {Total_{observed} Y = 1}$

### Specificity
* What is the ratio of correct negative predictions (Y = 0) to total negative predictions?
* _Negative predictive value (NPV)_ = $\frac{number of True -} {Total_{observed} Y = 0}$

---
# Specificity vs. Sensitivity
[insert hypothetical figure 
"Specificity and Sensitivity Change as the Probability Cutoff Changes"]

---
class: center, inverse

# Receiver Operating Characteristic (ROC) Curve

---
# ROC Curve: Gauging Accuracy of Model
* Plot of true positive rate against the false positive rate for the different possible cutoff points of a diagnostic test
* Illustrates the trade off between *sensitivity* and *specificity*
  - Increase in *sensitivity* will result in decrease in *specificity*, and vice versa
* The __area under the curve (AUC)__ measures *accuracy*
  - More accurate tests, the curve is closer to the left-hand border and the top border of the ROC

---
# Area Under the (ROC) Curve

```{r}
simple_roc <- function(labels, scores){
  labels <- labels[order(scores, decreasing=TRUE)]
  data.frame(TPR=cumsum(labels)/sum(labels), FPR=cumsum(!labels)/sum(!labels), labels)
}

set.seed(1)
sim_d <- function(N, noise=100){
  x <- runif(N, min=0, max=100)
  y <- 122 - x/2 + rnorm(N, sd=noise)
  dv <- factor(y > 100)
  data.frame(x, y, dv)
}
dv_d <- sim_d(500, 10)

test_set_idx <- sample(1:nrow(dv_d), size=floor(nrow(dv_d)/4))

test_set <- dv_d[test_set_idx,]
training_set <- dv_d[-test_set_idx,]
```


```{r}
test_set %>% 
  ggplot(aes(x=x, y=y, col=dv)) + 
  scale_color_manual(values=c("blue", "orange")) + 
  geom_point() + 
  ggtitle("DV to X")
```

---
# Examining the ROC curve

* Two classifiers that put the labels in the same order will have exactly the same ROC curve regardless of the absolute values of the scores.

* This is shown by comparing the ROC curve you get using either the ‘response’ or the ‘link’ predictions from a logistic regression model. 

* The ‘response’ scores have been mapped into the range between 0 and 1 by a sigmoid function and the ‘link’ scores have not.

```{r, echo = T}
fit_glm <- glm(dv ~ x, training_set, family=binomial(link="logit"))

glm_link_scores <- predict(fit_glm, test_set, type="link")

glm_response_scores <- predict(fit_glm, test_set, type="response")

score_data <- data.frame(link=glm_link_scores, 
                         response=glm_response_scores,
                         dv=test_set$dv,
                         stringsAsFactors=FALSE)
```

---
# Examining the ROC Curve

```{r plot-first, echo = FALSE, fig.cap="add caption"}
score_data %>% 
  ggplot(aes(x=link, y=response, col=dv)) + 
  scale_color_manual(values=c("black", "red")) + 
  geom_point() + 
  geom_rug() + 
  ggtitle("Both link and response scores put cases in the same order")
```

---
# Plotting the ROC Curve

```{r plot-second, echo = FALSE}
library(pROC)
plot(roc(test_set$dv, glm_response_scores, direction="<"),
     col="yellow", lwd=3, main="The turtle finds its way")
## 
## Call:
## roc.default(response = test_set$bad_widget, predictor = glm_response_scores,     direction = "<")
## 
## Data: glm_response_scores in 59 controls (test_set$bad_widget FALSE) < 66 cases (test_set$bad_widget TRUE)
## Area under the curve: 0.9037
glm_simple_roc <- simple_roc(test_set$dv=="TRUE", glm_link_scores)
with(glm_simple_roc, points(1 - FPR, TPR, col=1 + labels))
```

---
# Obtaining the AUC

.pull-left[
```{r plot-third, echo = FALSE}
set.seed(1)
N <- 2000
P <- 0.01
rare_success <- sample(c(TRUE, FALSE), N, replace=TRUE, prob=c(P, 1-P))
guess_not <- rep(0, N)
plot(roc(rare_success, guess_not), print.auc=TRUE)

## Call:
## roc.default(response = rare_success, predictor = guess_not)
## 
## Data: guess_not in 1978 controls (rare_success FALSE) < 22 cases (rare_success TRUE).
## Area under the curve: 0.5

simp_roc <- simple_roc(rare_success, guess_not)
with(simp_roc, lines(1 - FPR, TPR, col="blue", lty=2))
```
]

.pull-right[
```{r ref.label = 'plot-third', fig.show = 'hide'}
```
]

---

### AUC Guidelines:
* Will vary depending on the outcome variable, but here are some general guidelines:
  - AUC = 0.5 = Poor (equal to random chance)
  - 0.7 < AUC < 0.8 = Acceptable
  - 0.8 < AUC < 0.9 = Excellent
  - AUC > .9 = Outstanding

---
---
class: center, inverse

# Nested Data Applied to Logistic Regression

---

Binary independent variable/logistic regression

**Dataset: portugal.csv**

Statistics keep Portugal at Europe’s tail end due to its high student failure rates especially in core content areas such as math and the Portuguese language. Cortez and Silva (2008) collected student data from two Portuguese schools during the 2005- 2006 school year using school reports and student survey with a goal of developing models to predict student performance. The data include student grades, demographic, social, and school related features. Our goal here is to investigate the factors associated with student failure in Portuguese and the magnitudes of these associations. 

Student Portuguese grade is measured on a 20-point scale with zero being the lowest and 20 being the perfect grade. The grade can be further measured by a five-level classification system, with 16-10 being excellent, 14-15 being good, 12-13 being satisfactory, 10-11 being sufficient, and 0-9 being fail (our primary interest).   

The dataset contains 649 student observations and 18 variables

---
# Research question

What is the relationship between first period grade and failing at the end of the school year?

```{r}
por <- rio::import(here::here("data", "portugal.csv")) %>%
  select(school, female, age, first = por1, fail = por3_fail) %>% 
  drop_na() %>% 
  filter(first != 0)

head(por)
```

---
# Visualize the clustering nature of the data:

Count of students who failed Portuguese

```{r}
por %>% 
  mutate(fail = factor(fail, levels = c(0,1), labels = c("No", "Yes"))) %>% 
  ggplot(aes(fail)) +
  geom_bar(fill = "royalblue", width = 0.5, alpha = 0.8) +
  labs(x = "Failing Portuguese",
       y = "Number of Students")
```

---
# Count of students who failed Portuguese within each school

```{r}
por %>% 
  mutate(fail = factor(fail, levels = c(0,1), labels = c("No", "Yes"))) %>% 
  ggplot(aes(fail, fill = school)) +
  geom_bar(position = "dodge", width = 0.5, alpha = 0.8) +
  labs(x = "Failing Portuguese",
       y = "Number of Students")
```

---
# Relationship between first period grade and fail

```{r}
por %>% 
  ggplot(aes(first, fail)) +
  geom_point(color = "deeppink") +
  geom_jitter(alpha = 0.4,
              size = 0.5) +
  labs(x = "First period grade",
       y = "Failing Portuguese")
```

---

# Relationship between first period and fail within each school

```{r}
por %>% 
  ggplot(aes(first, fail, color = school)) +
  geom_point(color = "deeppink") + 
  geom_jitter(alpha = 0.4,
              size = 0.5) +
  labs(x = "First period grade",
       y = "Failing Portuguese")
```

---

# Logistic vs. OLS regression
|                 | Linear Least Squares | Binomial Regression |
|-----------------|----------------------|---------------------|
|Response variable| Normal distribution  | Number of successes in $n$ trials |
|Variance         | equal for each level of X | np(1−p) for each level of X |
|Model fitting    | μ=β0+β1x using Least Squares | log(p1−p)=β0+β1x using Maximum Likelihood |
|EDA              | plot X vs. Y; add line | find log⁡(odds) for several subgroups; plot vs. X|
|Comparing models | extra sum of squares F-tests; AIC/BIC | drop-in-deviance tests; AIC/BIC |
|Interpreting coef| β1= change in mean response for unit change in X | eβ1= percent change in odds for unit change in X|

---

# Logistic regression assumptions


---
# Key Takeaways


---
class: middle, inverse
# Synthesis and wrap-up

---
# Unit Goals

---
# To Dos

### Reading
-

### Assignments
- Assignment #X Due XX at 11:59PM
- Quiz #X Due on X XX at 5PM
