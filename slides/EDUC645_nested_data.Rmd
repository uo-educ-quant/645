---
title: "Introduction to Nested Data"
subtitle: "EDUC 645: General Linear Model II"
author: "TBD"
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{R, setup, include = F}
library(pacman)
p_load(here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, DiagrammeR, lme4, equatiomatic, performance, lmerTest, gtsummary)

i_am("slides/EDUC645_nested_data.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

```

# Roadmap

---
# Goals for the unit
- Introduce nested data structure (two-level, e.g., repeated measures within individuals, students within schools)
- Understand nesting/clustering means
- Demonstrate varying intercepts and slopes across clusters
- Practice fitting the same regression model independently for each cluster and create a table of intercepts and slopes across clusters
- Understand what it means for intercepts and slopes to vary across clusters
- Discuss the notion that regression coefficients may vary across different clusters
- Develop the concept of:
  - Fixed-effects as the aggregation of the different intercepts and slopes by taking an average of varying intercept and slopes across clusters
	- Random effects as the difference between cluster-specific intercept and slope and their averages across clusters
	- Covariance matrix of random-effects
- Discuss the implications of ignoring the variance of random-effects in terms of the inference for fixed-effects and statistical power

- Introduce 
	- Random intercept-only model
	  - its estimation through the R lmer package, 
		- interpret the model parameters and align them with the earlier discussion of fixed-effects and random-effects.
	- Intra-class correlation as a measure of within-cluster dependency
and how to use it to decide whether one needs to use multilevel modeling

---
# What is Nested Data?

levels of one factor vary only within the levels of another factor, that factor is said to be nested. 

For example, when measuring the performance of workers at several job locations, if the workers only work at one site, then the workers are nested within site. If the workers work at more than one location, we would say that workers are crossed with site.

---
# Where does it come from?
### Why do we need to think hierarchically?
1) Two realities exist within interventions:

(a) Effect implies change in individuals over time,

(b) Effect occurs in groups and organizational settings (e.g., dyads, groups, networks, neighborhoods, clinics, cities, countries).

--

2) Factors are nested across multiple levels; influence the organization of behavior.

---
# What happens if we ignore it?

### What errors result if we ignore multilevel effects?
#### Ecological Fallacy
- Systematic underestimation of group effects
- Inadequate intervention development and evaluation

#### Aggregation bias
- Attribute that an individual-level indicator is representative of the entire group

#### Biased estimation of statistical associations
- Misestimated standard errors
- Homogeneity of regression slopes

---
# Traditional Linear Regression Example
* Unit of analysis: Individual
* Examine between-individual variability
* Intercept and slope are the same for all groups
* Ignores inclusion of important group variables
* Residual correlation

---
class: middle, inverse

# Multilevel Models (MLM)

---
# Multilevel Models (MLM)

* Units of analysis: Individual and Group
* Examine between-individual and between-group variability
* The intercept and slopes may be different for individuals within and across groups
* These differences may be explained by cross-level interactions (differential effects due to individual and group-level characteristics)
* Allows for the inclusion of important individual and group variables
* No residual correlation

---
# Sampling and Design Considerations

### Formulating Research Questions

#### Several questions may be proposed and result in different multilevel equations:
- What is the association between UVI and number of partners among women in PR, after adjusting for clustering effects?
- Is there an association between UVI and living in a city where female condoms (FCs) are free and accessible?
- Do characteristics pertaining to a city modify the association between UVI and number of partners?

---
# Sampling and Design Considerations
### Design
#### What constitutes a group-level variable?
- Characteristic of
  - individual (provider, partner)
  - a setting (number of beds in hospital, allocated budget for HIV prevention in an agency)
  - catchment areas (Census, DHS)
- Policies (% of budget allocated to abstinence-only)

--

#### How are group-level variables defined?
- Aggregating individual-level characteristics into groups (school district SES)
- Developing group-level measures (mental illness stigma in a school district)

---
# Sampling and Design Considerations
### Sampling
#### Calculating Statistical Power is similar to “traditional” analyses
- Formulate the hypotheses to be tested
- Compute or Estimate the ICC
- Determine the variable and outcome of interest
- Determine the sample frame based on the I.V.(s)

--

#### Sampling clusters or sampling individuals?
- Determine the number of parameters in the model
- Calculate the number of observations needed for each cluster

--

#### Law of Diminishing Returns

---
class: middle, inverse

# Nested and crossed random effects in "lme4"

---
# Nested and crossed random effects in "lme4"

Packages particularly needed for this unit: `lme4`, `equatiomatic`, `performance`, `lmerTest`

---
# The Data: Stanford Education Data Archive (SEDA)

Launched in 2016 to provide nationally comparable, publicly available test score data for U.S. public school districts, allowing scientific inquiries on the relationships between educational conditions, contexts, and outcomes (especially student math/ELA achievements) at the district-level across the nation.

Variable include measures of:
- academic achievement 
- achievement gaps for school districts and counties
- district-level measures of racial and socioeconomic composition
- racial and socioeconomic segregation patterns
- other features of the schooling system

Data set:
- district-level data for 103 Oregon school districts, year 2017-18 data
- Observations with missing values on any of the key variables were deleted for simplification

---
# Inspect the data 

What does each row/observation represent?

```{r, echo = FALSE, fig.cap="add caption"}
seda <- rio::import(here::here("data", "seda_oregon.csv")) %>%
  mutate(subject = recode(subject, 'mth' = "Math", 'rla' = "Reading"))

head(seda)
```

---

# Descriptives
```{r, echo = FALSE, fig.cap="add caption"}
seda %>%
  select(-district) %>% 
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} / {N} ({p}%)"),
    label = list(subject ~ "Subject",
                 grade ~ "Grade",
                 achievement ~ "Achievement",
                 gap_gender ~ "Achievement Gender Gap",
                 percent_ell ~ "ELL Percentage",
                 percent_sped ~ "SPED Percentage",
                 percent_frl ~ "FRL Percentage")) %>%
  modify_header(label ~ "**Key Variables**")
```

---
# Understand the clustering nature

Let's start with a single variable: Oregon districts' achievement score 

Are we losing information by simply looking at district achievement across subject and grade?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>% 
  group_by(district) %>% 
  mutate(mean = mean(achievement)) %>%
  ungroup() %>% 
  select(district, mean) %>%
  ggplot(aes(district, mean)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```


???
Note that districts are "randomly" selected by course developer

---

Does achievement differ by subject?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>% 
  group_by(district, subject) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, mean) %>%
  ggplot(aes(district, mean, color = subject)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

---

Differ by grade?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>% 
  group_by(district, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, grade, mean) %>%
  ggplot(aes(district, mean, color = grade)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

---

Differ by grade AND subject?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>% 
  group_by(district, subject, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, grade, mean) %>%
  ggplot(aes(district, mean, color = grade)) +
  facet_wrap(vars(subject)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

---

Alternatively, 
Can you describe the "clustering" nature of the data in more details now?

IMPORTANTLY, should we keep in mind of this unique feature when we answering research questions, e.g., about relations between two variables?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>% 
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6")) %>% 
  group_by(district, subject, grade) %>% 
  mutate(mean = mean(achievement)) %>% 
  ungroup() %>% 
  select(district, subject, grade, mean) %>%
  ggplot(aes(district, mean, color = subject)) +
  facet_wrap(vars(grade)) +
  geom_point() +
  labs(x = "District",
       y = "Achievement")
```

---
# Relationship across grade and subject:

For example, let's look at relationship between percentage of ELL and achievement

```{r, echo = FALSE, fig.cap="add caption"}
seda %>%
  group_by(district) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) + 
  labs(x = "ELL Percentage",
       y = "Achievement")
```

---

Does this relationship differ by subject?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>%
  group_by(district, subject) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement, color = subject)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Achievement")
```

---

Does this relationship differ by subject AND grade?

```{r, echo = FALSE, fig.cap="add caption"}
seda %>%
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6")) %>% 
  group_by(district, subject, grade) %>% 
  mutate(achievement = mean(achievement)) %>% 
  ungroup() %>% 
  ggplot(aes(percent_ell, achievement, color = subject)) +
  facet_wrap(vars(grade)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Achievement")
```

* What is your current understanding of clustered data? 
* Is there a single answer to the relationship between percentage of ELL students and achievement? 

???

Expect students to realize that there is no universal answer; depends on what you look at, what cluster/clusters you want to include, and model specifications

---
# Modeling the relationship between two variables

**For this introductory course, we only focus on two-level clustered data.**

From now on, we pull out the cluster of subject, and focus on math achievement only.

**Overarching inquiry: What is the relationship between percentage of ELL students and math achievement in Oregon districts?**

What model/models can we fit to answer the question? 

```{r, echo = FALSE}
district <- seda %>%
  filter(subject == "Math") %>% 
  select(-subject) %>% 
  select(math = achievement, everything()) %>% 
  mutate(grade = recode(grade, '3' = "G3", '4' = "G4", '5' = "G5", '6' = "G6"))
```

---
class: middle, inverse

# Fixed Effects & Random Effects

---

# Fixed effects model

* Assume a common intercept for all grades. 

--

```{r, echo = FALSE, fig.cap="add caption"}
district %>% 
  ggplot(aes(percent_ell, math)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) +
  labs(x = "ELL Percentage",
       y = "Math")
```

---

# Fixed effects model

How to interpret these parameters?

```{r, echo=T}
m1 <- lm(math ~ percent_ell, district)
summary(m1)
```

--

[insert interpretation]

---
# Fixed effects model

How to interpret these parameters?

```{r, echo=T}
coef(m1)
```

--

[insert interpretation]

---
# Random effects model

* Allow the intercept to differ across grades

```{r, echo = F}
district %>% 
  ggplot(aes(percent_ell, math, color = grade)) +
  geom_smooth(method='lm', se = 0) +
  geom_point(alpha = 0.1) + 
  labs(x = "ELL Percentage",
       y = "Math")
```

-- 

What parameters changed in the plot? 

-- 

 - Intercept: each grade has a unique intercept
 - Slope: slope changes accordingly

**In fact, mixed-effects models can do more!** 

???

Another way to answer the question is allowing the intercept to differ across grades - a unique intercept for each grade.

---
`lme4` package: `lmer` function models the data in R:

Model 1. Simple linear regression model for comparison

```{r}
m1 <- lm(math ~ percent_ell, district)
coef(m1)
```

Model 2. Multilevel model with *random __intercepts__*
    - What parameter differs across grades? what parameter remains the same?

```{r, echo=TRUE}
m2 <- lme4::lmer(math ~ percent_ell + (1|grade), district)
summary(m2)
coef(m2)$grade
```

*R Notes: starting the usage of {equatiomatic} package*
The notion being used through this unit:
```{r}
equatiomatic::extract_eq(m2)
```

---
# Model 3. Multilevel model with *random __slopes__* 

* **Note**: this comparison is primarily for instructive purposes
* How do you interpret the parameters now?
 
```{r, echo=TRUE}
m3 <- lmer(math ~ 1 + (0 + percent_ell|grade), district)
summary(m3)
coef(m3)$grade
# extract_eq(m3) doesn't work here
```

---
Model 4. Multilevel model with *random __intercepts__ and __slopes__*

* How about the parameters for this model specification?
* Specify the relationship between percentage of ELL and math achievement for grades 3, 4 & 6

```{r, echo=TRUE}
m4 <- lmer(math ~ percent_ell + (1 + percent_ell|grade), district)

summary(m4)
```

```{r, echo=TRUE}
coef(m4)$grade
```

```{r, echo=TRUE}
extract_eq(m4)
```

--

What did we learn so far? Describe the differences between model 1 (simple linear regression) and a model with
* Random intercepts, model 2
* Random slopes, model 3
* Random intercepts and slopes, model 4

---
# Fixed effects vs random effects

If we put the two previous plots together:

```{r, echo = FALSE, fig.cap="add caption"}
district %>% 
  ggplot(aes(percent_ell, math)) +
  geom_smooth(method='lm', se = 0, color = "deeppink") +
  geom_point(alpha = 0.1) + 
  geom_smooth(aes(color = grade), method='lm', se = 0) +
  geom_point(aes(color = grade), alpha = 0.1) +
  scale_color_hue(l=80, c=30) +
  labs(x = "ELL Percentage",
       y = "Math")
```

* what does the bright red line represent? 
* what do the other four lines represent?

---

Also a review of the relationship between fixed effect (model 1) and random effects (model 4) parameters:

```{r}
coef(m1)[1]
mean(unlist(coef(m4)$grade[1]))
```

```{r}
coef(m1)[2]
mean(unlist(coef(m4)$grade[2]))
```

What might be the reason behind these?

Summary:
* **Fixed effect** represents the aggregation of the different intercepts and slopes by taking an average of varying intercept and slopes across clusters
 
* **Random effects** represent the difference between cluster-specific intercept and slope and their averages across clusters

---
class: middle, inverse

# Interdependence and the Intraclass Correlation Coefficient (ICC)

---
# What does “independence” mean?
#### The observation of one participant does not depend on the response of other participants

#### What happens to independence when:
- We collect data across multiple sites?
- Collect observations from the same individual over time?

---
# Intraclass Correlation

**Intraclass correlation coefficient**: Proportion of total variability in the outcome that occurs between groups.

i.e., the ICC is calculated as a ratio

ICC = $(variance of interest) / (total variance) = (variance of interest) / (variance of interest + unwanted variance)

--

* Larger ICC = More inequality between groups

???
The greater the ICC, the greater the reflection of inequality between groups.

---

# Intraclass Correlation
### Common methods to address the ICC “issue”
- Ecologic Regression
- Stratified Regressions
- Group fixed-effects Model
- Contextual Model
- Hierarchical Linear Models

--

### Group-level modeling

--

### Repeated-measured modeling (“Growth curves”)

---
# Manually Calculate ICC

[insert example]

---
# When modeling random effects becomes necessary?
## Unconditional model and ICC

We estimate a baseline model (model 0) to see how much variance in math is attributable to between-grade variation

```{r}
m0 <- lmer(math ~ 1 + (1 | grade), district)
extract_eq(m0)
summary(m0)
```

---
#Interpreting the ICC

*R notes: starting the {performance} package usage*

```{r}
performance::icc(m0)
```

Interpretation: Approximately 64.5% of the variance in math achievement lies between grades. 

Conclusion: The fixed effects model masks important information regarding differences in grade-level achievement.

???

Specifically, about 64.5% of the variance in math achievement lies between grades. 

At this point, the fixed effects model aggregating grade-level achievement to a grand mean is masking important information regarding grade-level achievement.
 
allow you to investigate changes over time

---
class: middle, inverse

# Assessing Model Fit

---
# Choosing the preferred model 
We have several models: 
* Fixed effects model (simple linear regression, model 1) 
* Four random effects (i.e., mixed-effects) models
  - Unconditional model (model 0)
  - Random intercepts (model 2)
  - Random slopes (model 3)
  - Random intercepts and slopes (model 4)

How do we know which one is preferred?

--
Indices and Methods to assess Model Fit:
* Root Mean Square Estimate (RMSE)
* Chi-squared significance test of the change in the model deviance
* Information criteria (i.e., AIC/BIC)
* Cross validation procedures

???
So far, we have one fixed effects model, but
how do we know which one is preferred?

---

Compare model 1 and model 4:

```{r}
performance::compare_performance(m1, m4) %>% 
  print_md()
```

```{r}
test_likelihoodratio(m1, m4) %>% 
  print_md
```

Compare model 2 and model 4:

```{r}
performance::compare_performance(m2, m4) %>% 
  print_md()
```

```{r}
test_likelihoodratio(m2, m4) %>% 
  print_md
```

--

**Interpretation**: Model 4 performs best

_**HOWEVER**_ model 4 doesn't perform much better than model 2 

**Conclusion:** Choose model 2 for *parsimonious* reason.

???

Model 4 doesn't perform much better than model 2 (identical RMSE;
- non-significant chi squared test of the change in the model deviance; 
- also visually confirmed in the previous random-intercept random-slope plot that the slope of the fitted line didn't vary too much across four grades), so for this little exercise, I would choose model 2 for parsimonious reason.

---

# Model Building and Parsimony



---
class: center, inverse

# Nested Data Applied to Logistic Regression

---

Binary independent variable/logistic regression

**Dataset: portugal.csv**

Statistics keep Portugal at Europe’s tail end due to its high student failure rates especially in core content areas such as math and the Portuguese language. Cortez and Silva (2008) collected student data from two Portuguese schools during the 2005- 2006 school year using school reports and student survey with a goal of developing models to predict student performance. The data include student grades, demographic, social, and school related features. Our goal here is to investigate the factors associated with student failure in Portuguese and the magnitudes of these associations. 

Student Portuguese grade is measured on a 20-point scale with zero being the lowest and 20 being the perfect grade. The grade can be further measured by a five-level classification system, with 16-10 being excellent, 14-15 being good, 12-13 being satisfactory, 10-11 being sufficient, and 0-9 being fail (our primary interest).   

The dataset contains 649 student observations and 18 variables

---
# Research question

What is the relationship between first period grade and failing at the end of the school year?

```{r}
por <- rio::import(here::here("data", "portugal.csv")) %>%
  select(school, female, age, first = por1, fail = por3_fail) %>% 
  drop_na() %>% 
  filter(first != 0)

head(por)
```

---
# Visualize the clustering nature of the data:

Count of students who failed Portuguese

```{r}
por %>% 
  mutate(fail = factor(fail, levels = c(0,1), labels = c("No", "Yes"))) %>% 
  ggplot(aes(fail)) +
  geom_bar(fill = "royalblue", width = 0.5, alpha = 0.8) +
  labs(x = "Failing Portuguese",
       y = "Number of Students")
```

---
# Count of students who failed Portuguese within each school

```{r}
por %>% 
  mutate(fail = factor(fail, levels = c(0,1), labels = c("No", "Yes"))) %>% 
  ggplot(aes(fail, fill = school)) +
  geom_bar(position = "dodge", width = 0.5, alpha = 0.8) +
  labs(x = "Failing Portuguese",
       y = "Number of Students")
```

---
# Relationship between first period grade and fail

```{r}
por %>% 
  ggplot(aes(first, fail)) +
  geom_point(color = "deeppink") +
  geom_jitter(alpha = 0.4,
              size = 0.5) +
  labs(x = "First period grade",
       y = "Failing Portuguese")
```

---

# Relationship between first period and fail within each school

```{r}
por %>% 
  ggplot(aes(first, fail, color = school)) +
  geom_point(color = "deeppink") + 
  geom_jitter(alpha = 0.4,
              size = 0.5) +
  labs(x = "First period grade",
       y = "Failing Portuguese")
```

---

# Summary
### Multilevel Modeling allows us to answer complex questions adequately if:
- An appropriate study design is conceptualized
- Measures across levels are identified from existing datasets or carefully operationalized

### Multilevel Modeling may be appropriate if residual correlations exist due to violations of independence
- Benefit of partitioning variance even when Level-1 or Level-2 variables will not be modeled