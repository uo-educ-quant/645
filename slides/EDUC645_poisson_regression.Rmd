---
title: "Poisson Regression"
subtitle: "EDUC 645: General Linear Model II"
author: "TBD"
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  editor_options: 
  chunk_output_type: console
---

```{R, setup, include = F}

knitr::opts_chunk$set(echo = TRUE)
if (!require(pacman)) install.packages('pacman', repos = 'https://cran.rstudio.com')
pacman::p_load(here, tidyverse, ggplot2, xaringan, kableExtra, foreign, xaringanthemer, dplyr, knitr, lfe, arsenal, ggpubr, broom, stargazer, fixest, gtsummary, huxtable, scales, AER)
theme_set(theme_classic())


i_am("slides/EDUC645_poisson_regression.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

red_pink <- "#e64173"
turquoise = "#20B2AA"
orange = "#FFA500"
red = "#fb6107"
blue = "#3b3b9a"
green = "#8bb174"
grey_light = "grey70"
grey_mid = "grey50"
grey_dark = "grey20"
purple = "#6A5ACD"
slate = "#314f4f"
extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".red-pink" = list(color= "red_pink"),
  ".grey-light" = list(color= "grey_light"),
  ".purple" = list(color = "purple"),
  ".small" = list("font-size" = "90%"))
write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 5,
  fig.width = 8,
  warning = F,
  message = F
)

```

# Roadmap

---
# A Motivating Question

This dataset was drawn from the China Education Panel Survey (CEPS), China’s first nationally representative, longitudinal survey of middle school students. CEPS first wave was conducted during school year 2013-2014 and a stratified, four-step random sampling procedure was implemented to draw a random sample of middle schools (N=112) from the nation and collect rich data from school administrators, teachers, students, and parents. This school-level dataset is limited to 45 schools that have eight teacher participants and no missing values on any key variables. Our primary goal with this dataset is to investigate the school-level factors associated with teacher job satisfaction that is measured by the count of teachers who feel satisfied with their job and their school. 

Research inquiry: relationship between class size and job satisfaction

---
# The dataset 

**Dataset: ceps_sch.csv**

```{r, echo = F}
ceps <- rio::import(here::here("data", "ceps_sch.csv")) 

ceps %>% 
  filter(row_number() < 6) %>% 
  kable()
```


 - *schids*, school identifier
 - *njobsatis*, number of teachers who answered yes to the question of whether to choose being a teacher if given other job options
 - *nschsatis*, number of teachers who answered yes to the question of whether to choose the current school if being allowed to move to other schools
 - *rural*, categorical measure of proportion of rural students in school; 1=lower than 25%, 2=25% to 60%, 3=60% to 80%, 4=higher than 80%
 - *clsize*, average class size
 - *computer*, number of computers available to students
 - *ctyeduz*, neighborhood average years of education (standardized)

---
# Summary statistics 

```{r, echo = F}
ceps %>% 
  select(-schids) %>%
  select(njobsatis, nschsatis, everything()) %>% 
  mutate(rural = factor(rural, levels = c(1,2,3,4), labels = c("lower than 25%", "25% to 60%", "60% to 80%", "higher than 80%"))) %>% 
  tbl_summary(
    type = list(c("clsize", "ctyeduz", "computer") ~ "continuous",
                c("njobsatis", "nschsatis", "rural") ~ "categorical"),
    statistic = list(all_continuous() ~ "{mean} ({min}, {max})",
                       all_categorical() ~ "{n} / {N} ({p}%)"),
    label = list(njobsatis ~ "Number of teachers satisfied with job",
                 nschsatis ~ "Number of teachers satisfied with school",
                 rural ~ "Proportion of rural students",
                 clsize ~ "Average class size",
                 computer ~ "Number of computers",
                 ctyeduz ~ "Neighborhood average years of education (standardized)")
    )
```

---
# Visualizations

## The two teacher satisfaction measures

Job satisfaction:

```{r, echo = F}
ceps %>% 
  ggplot(aes(njobsatis)) +
  geom_bar(fill = "steelblue") +
  labs(x = "Number of teachers satisfied with job",
       y = "Number of schools") + 
  scale_y_continuous(labels = label_number(accuracy = 1))
```

---
# Visualizations

Satisfaction towards school:

```{r, echo = F}
ceps %>% 
  ggplot(aes(nschsatis)) +
  geom_bar(fill = "cadetblue") +
  labs(x = "Number of teachers satisfied with school",
       y = "Number of schools") + 
  scale_y_continuous(labels = label_number(accuracy = 1))
```
Henceforce investigating job satisfaction (njobsatis). We may use job satisfaction (njobsatis) as outcome in the class and school satisfaction (nschsatis) in the lab or assignment.

---
# Why simple linear regression may not be ideal for count data

Do you think a linear fitted line is a good way to describe the relationship between these two variables?

```{r, echo = F}
ceps %>% 
  ggplot(aes(clsize, njobsatis)) +
  geom_point() +
  geom_smooth(method = "lm", alpha = 0, color = "orangered") +
  labs(x = "Average class size",
       y = "Number of teachers satisfied with job") + 
  scale_y_continuous(labels = label_number(accuracy = 1))
```

---
# 

An important reason why a linear least squares regression model doesn't work for Poisson data is the violation of equal variance assumption, see the plot below:

```{r, echo = F}
ols <- lm(njobsatis ~ clsize, ceps)

plot(density(resid(ols)))
```

---

```{r}
# try to replicate Figure 4.1 in textbook (in progress)

# get the residuals of linear regression
ceps$residuals_ols <- residuals(ols)
# get the residuals of poisson regression
ceps$residuals_glm <- ceps$njobsatis - 0.1 * ceps$clsize
```

---
# Count Data

What about examining predictors of outcomes related to a rate or number of events:
* the number of times an event occurs during a given timeframe?
* the number of people in line at the grocery store?

These kinds of questions draw from count data
* Discrete data with non-negative integer values that count a particular outcome according to a defined parameter of time/space

**How does this definition differ from binomial data?**

--

**How does this definition differ from continuous data?**

---

# Normal distribution vs. Count data

.pull-left[
```{r, echo=F}
# create a sequence -3 to +3 with .05 increments
xseq <- seq(-3, 3, .05)

# generate a Probability Density Function
densities <- dnorm(xseq, 0, 1)

# plot the graph
plot(xseq, densities, col = "blue", xlab = "", ylab = "Density", type = "l", lwd = 2)
# col: changes the color of line
# 'xlab' and 'ylab' are labels for x and y axis respectively
# type: defines the type of plot. 'l' gives a line graph
# lwd: defines line width
```
]

--

.pull-right[
```{r, echo=F}
# create a sequence -3 to +3 with .05 increments
xseq <- seq(0, 20, 1)

# generate a Probability Density Function
densities <- dpois(xseq, lambda = 3)

# plot the graph
plot(xseq, densities, col = "blue", xlab = "", ylab = "Density", type = "l", lwd = 2)
# col: changes the color of line
# 'xlab' and 'ylab' are labels for x and y axis respectively
# type: defines the type of plot. 'l' gives a line graph
# lwd: defines line width
```
]

---
# Options for Analysing Count Data

| Model Type        | Benefits                           |  Drawbacks                      |
|-------------------|------------------------------------|---------------------------------|
| Negative binomial | Accounts for overly-dispersed data |                                |
| Zero-inflated models | Accounts for a large number of zero's (e.g., # of cigarettes smoked by general population)| |

Poisson regression – Poisson regression is often used for modeling count data. Poisson regression has a number of extensions useful for count models.
Negative binomial regression – Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean. It can be considered as a generalization of Poisson regression since it has the same mean structure as Poisson regression and it has an extra parameter to model the over-dispersion. If the conditional distribution of the outcome variable is over-dispersed, the confidence intervals for coefficients in Negative binomial regression are likely to be wider as compared to those from a Poisson regression.
Zero-inflated regression model – Zero-inflated models attempt to account for excess zeros. In other words, two kinds of zeros are thought to exist in the data, “true zeros” and “excess zeros”. Zero-inflated models estimate two equations simultaneously, one for the count model and one for the excess zeros.
OLS regression – Count outcome variables are sometimes log-transformed and analyzed using OLS regression. Many issues arise with this approach, including loss of data due to undefined values generated by taking the log of zero (which is undefined) and biased estimates.

[and explain tradeoffs across approaches!]

---
# Poisson Distribution

* A discrete probability distribution is used to describe the off occurrence of unlikely events in a large number of independent trials

* Poisson is a good approximation to the binomial distribution when the probability is small and the number of trials is large

* It expresses the probability of a number of events occurring in a fixed period of time if these events occur with a known average rate and are independent of the time since the last event
Examine if we want to know "how many of X in what amount of time"

---
# Poisson Distributions

```{r, echo=F, fig.height=5.5}
lambdas <- c(10, 20, 30, 40)

pois_plot <- ggplot(data = data.frame(x = 0:75)) +
    lapply(lambdas, 
           function(l) geom_point(aes(x = x, 
                                      y = dpois(x, lambda = l), 
                                      col = factor(l)))) +
    lapply(lambdas, 
           function(l) stat_function(fun = dnorm, 
                                     args = list(mean = l, sd = sqrt(l)), 
                                    aes(x = x, col = factor(l))))
pois_plot 
```

---

```{r, echo=F}
par(mfrow = c(3, 2), mar = c(1, 1, 2, 1), oma = c(4, 4, 2, 0))
for (i in c(1, 2, 3, 5, 7, 9)) {
    curve(dpois(x, lambda = i), from = 0, to = 18, n = 19, type = "p", pch = 15,
        cex = 1.5, xlim = c(0, 19), ylim = c(0, 0.4), xlab = "", ylab = "")
    text(x = 15, y = 0.3, substitute(lambda == x, list(x = i)), cex = 2)
}
mtext("Probability Mass Function for Poisson Distribution", line = 0.5,
    outer = TRUE, cex = 1.2)
mtext(expression(P(X == x)), side = 2, line = 1.5, outer = TRUE)
mtext("X", side = 1, line = 1.5, outer = TRUE)
```

---
# Poisson Vs. Normal Distribution

|Poisson Distribution |	Normal Distribution|
|----------------------------|---------------------------------|
|Used for count or rate data |	Used for continuous variables |
|Skewed by values of lambda	 | Bell-shaped curve symmetric around the mean.|
|Variance = Mean	| Variance and mean are different parameters; mean, median and mode are equal |

---
# Poisson Distribution: Dispersion


---
# Time

Time: normalizes the count variable that is observed
- Number of accidents per day, per year, per week
- Units of time, length of time, or other unit
Number of accidents per mile, students per district

---
# Rate

Rate = # of events/unit of time

Sometimes rescaled so that the number of cases per unit is a whole number
Rate $\neq$ probability

|       |Rate                 |Probability|
|-------|---------------------|-----------|
| Units |Include unit of time |Do not have a unit|
| Range of values |Can be >1            |Between 0 and 1|

---
# Comparing Rates

Suppose we want to compare rate of Y at two different sites (X groups) 
We have to assume that incidents occurred at similar rates throughout the year
Typically organize information about counts and time in a table:

|	       |Count|Time |
|--------|-----|-----|
|Group 1 | N1	 |T1   |
|Group 2 | N2	 |T2   |

---
# Steps to comparing rates:

### 1. Calculate rates in both groups
$$Rate = \frac{n_{events}}{unit_{time}}$$

### 2. Calculate Rate Ratio (RR)
$$RR = \frac{Rate_1}{Rate_2}$$

### 3. Conduct test of hypothesis to see is RR $\neq$ 1

$$H_0: RR = 1$$
$$H_a: RR \neq 1$$

$$z = \frac{ln(RR)}{\sqrt{(\frac{1}{n_1}+\frac{1}{n_2}}}$$
* Get $p$-value
* Get CI for RR
*	Draw conclusions
	
---

# [insert examples]

---
class: middle, inverse
# Modeling Poisson Distribution
.left[Poisson Regression]

---
# Poisson Regression V. Logistic Regression

- Like logistic regression, the underlying mathematics and underlying probability distribution theory are different from OLS regression
  - Relies on the same parameters of the GLM

* Logistic regression models the **log odds of _an event_**

* Poisson regression models the **natural log of _an expected count_**
  - Negative predicted values non-issue (negative values correspond to expected counts between 0 and 1)

---
# Poisson Regression 

* Helps us analyze both count data and rate data 
  - Can determine which explanatory variables (X values) have an effect on a given response variable (Y value, the count or a rate). 
  - For example, school districts could use to better predict the number of students who receive free/reduced lunch.

---
# Assumptions pt. 1
* Response Variable: The response variable is a count per unit of time or space, described by a Poisson distribution.
* Independence: The observations must be independent of one another.
* Mean = Variance by definition, the mean of a Poisson random variable must be equal to its variance.
* Linearity: The log of the mean rate, log(λ), must be a linear function of x.

---
# Assumptions pt. 2

The outcome (Y) is a count (positive integer)
* Ex. the number of people in a subgroup of a population who have a learning disorder
Requires a unit of time:
* E.g., number of accidents per day, number of exposed per year

Count data can also be expressed as rate data
* the number of times an event occurs within a time frame can be expressed as:
  - raw count (i.e. “In a day, we eat three meals”)
  - rate (“We eat at a rate of 0.125 meals per hour”)

---
# Poisson regression assumptions

number of teachers satisfied with their job still demonstrate Poisson distribution when grouped by class size:

```{r, echo = F}
# table(ceps$clsize)
cuts = cut(ceps$clsize,
           breaks=c(10, 30, 50, 70))
data.frame(cuts, ceps) %>% 
  ggplot(aes(njobsatis)) +
  geom_histogram(color = "royalblue") +
  facet_wrap(cuts) +
  labs(x = "Number of teachers satisfied with job",
       y = "Number of schools")
```

---
# Poisson regression assumptions

```{r, echo = F}
data.frame(cuts, ceps) %>% 
  ggplot(aes(njobsatis, fill = cuts)) +
  geom_histogram(position = "fill") +
  labs(x = "Number of teachers satisfied with job",
       fill = "Groups of class size") +
  scale_fill_brewer(palette="Dark2")
```

---
# Poisson regression assumptions
Examine whether the mean is equal to variance assumption for Poisson random variables:

```{r, echo = F}
data.frame(cuts, ceps) %>% 
  group_by(cuts) %>% 
  summarise(mean = mean(njobsatis),
            var = var(njobsatis),
            n = n()) %>% 
  kable(col.names = c("Class size groups", "Mean", "Variance", "n")) 
```

---
# Poission regression assumptions

Examine dispersion

equidispersion in Poisson regressions against the alternative of overdispersion and/or underdispersion

More formally, the dispersion test:

```{r}
dispersiontest(glm(njobsatis ~ clsize, family = poisson, ceps))
```

---
# Poisson regression assumptions

Third, check for the linearity assumption:

```{r, echo = F}
ceps %>% 
  group_by(clsize) %>% 
  summarize(mean = mean(njobsatis),
            logmean = log(mean),
            n = n()) %>% 
  ggplot(aes(clsize, logmean)) +
  geom_point(color = "grey60") +
  geom_smooth(method = "loess", size = 1.2, color = "firebrick", alpha = 0.2) +
  labs(x = "Average class size",
       y = "Log of the empirical mean of number of teacher satisfied")
```

---
# Interpretation of Model Parameters

$$\log(\lambda) = \beta_0 + \beta_1X$$
$\lambda$: Average number of occurrences per unit of time or space, as a function of one or more covariates

$\beta_0$: log of the rate for the reference group

$\beta_1$: log of the rate ratio between a given group and the reference group

$X$:predictor variable

---
# Rates Accounting for other factor(s)
Poisson regression allows us to study how rates of an even vary by characteristics of the groups of interest
$$\ln(Rate) = \beta_0 + \beta_1X$$

- $E[Y]$: expected number of events

- $X$: predictor variable

- $\beta_0$: natural log of the rate for the reference group

- $\beta_1$: natural log of the rate ratio between a given group and the reference group
	- Similar to the logistic regression where the coefficient was the natural log of the OR

--

### alternatively written...

$$\ln(\frac{E[Y]}{Time}) = \beta_0 + \beta_1X$$

$$\ln(E[Y]) - \ln(Time) = \beta_0 + \beta_1X$$

$$\ln(E[Y]) = \beta_0 + \beta_1X + \ln(Time)$$

- $\ln(Time)$: *offset variable* takes into account the rate of change over time

---
# Interpreting Parameter Estimates
Poisson regression coefficient represents the *change in response corresponding to a one unit difference in the corresponding predictor.* 

[Make sure to devote substantial time to work on interpreting what the parameter estimates mean]

The output begins with echoing the function call. The information on deviance residuals is displayed next. Deviance residuals are approximately normally distributed if the model is specified correctly.In our example, it shows a little bit of skeweness since median is not quite zero.
Next come the Poisson regression coefficients for each of the variables along with the standard errors, z-scores, p-values and 95% confidence intervals for the coefficients.

The coefficient for math is .07. This means that the expected log count for a one-unit increase in math is .07. The indicator variable progAcademic compares between prog = “Academic” and prog = “General”, the expected log count for prog = “Academic” increases by about 1.1. The indicator variable prog.Vocational is the expected difference in log count ((approx .37)) between prog = “Vocational” and the reference group (prog = “General”).
The information on deviance is also provided. We can use the residual deviance to perform a goodness of fit test for the overall model. The residual deviance is the difference between the deviance of the current model and the maximum deviance of the ideal model where the predicted values are identical to the observed. Therefore, if the residual difference is small enough, the goodness of fit test will not be significant, indicating that the model fits the data. We conclude that the model fits reasonably well because the goodness-of-fit chi-squared test is not statistically significant. If the test had been statistically significant, it would indicate that the data do not fit the model well. In that situation, we may try to determine if there are omitted predictor variables, if our linearity assumption holds and/or if there is an issue of over-dispersion.


???
Like other regression coefficients, a Poisson regression coefficient represents the change in response corresponding to a one unit difference in the corresponding predictor. Here, the response is expected (natural) logged count.

---
# Poisson regression estimator

Poisson regression allows us to study how rates of an even vary by characteristics of the groups of interest
$$\ln(Satifaction) = \beta_0 + \beta_1ClassSize$$

```{r, echo = F}
m1 <- glm(njobsatis ~ clsize, family = poisson, ceps)
m2 <- glm(njobsatis ~ clsize + rural + computer + ctyeduz, family = poisson, ceps)
```

```{r, echo = F}
list(m1, m2) %>% 
  huxreg()
```

---
# Poisson regression  Model fit

```{r}
anova(m1, m2, test = "Chisq")
```

---
# Interpreting Coefficients

---
# Diagnostics/Assessing Model Fit

Compared to OLS estimators:

```{r, echo = F}
m3 <- lm(njobsatis ~ clsize, ceps)
m4 <- lm(njobsatis ~ clsize + rural + computer + ctyeduz, ceps)

huxreg(
  "Poisson" = m1,
  "Poisson (covariates)" = m2,
  "OLS" = m3,
  "OLS (covariates)" = m4,
  coefs = c("Average class size" = "clsize",
            "Proportion of rural students" = "rural",
            "Number of computers" = "computer",
            "Neigbhorhood education (standardized)" = "ctyeduz")
  )
```

---

# OLS regression vs. Poisson regression

|                 | Linear Least Squares | Poisson Regression |
|-----------------|----------------------|--------------------|
|Response variable| Normal distribution  | Discrete counts    |
|Variance         | equal for each level of X | Equal to the mean for each level of X |
|Model fitting    | $\mu=\beta_0+\beta_1x$ with Least Squares | $\log(\lambda)=\beta_0+\beta_1x$ with Maximum Likelihood |
|EDA              | plot X vs. Y; add line | Find $\log(\bar{y})$ for several subgroups; plot vs. X|
|Comparing models | extra sum of squares F-tests; AIC/BIC | drop-in-deviance tests; AIC/BIC |
|Interpreting coef| $\beta_1$ = change in mean response for unit change in X | $e^{\beta_1}$= percent change in $\lambda$ for unit change in X|


---
# Robust standard Errors

Cameron and Trivedi (2009) recommended using robust standard errors for the parameter estimates to control for mild violation of the distribution assumption that the variance equals the mean. We use R package sandwich below to obtain the robust standard errors and calculated the p-values accordingly. Together with the p-values, we have also calculated the 95% confidence interval using the parameter estimates and their robust standard errors.

---
# Key Takeaways


---
class: middle, inverse
# Synthesis and wrap-up

---
# Unit Goals

---
# To Dos

### Reading
-

### Assignments
- Assignment #X Due XX at 11:59PM
- Quiz #X Due on X XX at 5PM