---
title: "Count Outcomes and Poisson Regression"
subtitle: "EDUC 645 (Spring 2023)"
#author:
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  editor_options: 
  chunk_output_type: console
---

```{R, setup, include = F}
library(pacman)
p_load(NHANES, easystats, emmeans, DHARMa, ggeffects,
       here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, lfe, arsenal, ggpubr, stargazer, fixest, gtsummary, huxtable, aod)

i_am("slides/EDUC645_poisson_regression_Sp23.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 5,
  fig.width = 8,
  warning = F,
  message = F
)

NHANES_data1112 <- NHANES::NHANES %>% 
  select(ID, SurveyYr, Gender, Age, AgeDecade, Race3, Education, Poverty, Diabetes, DaysMentHlthBad, Depressed, PhysActive, SleepTrouble) %>% 
  mutate(Race_Eth = as_factor(case_when(Race3 == "Mexican" | Race3 == "Hispanic" ~ "Hispanic/Latino",
                                        TRUE ~ Race3)),
         PhysActive = as_factor(case_when(PhysActive == "No" ~ "Inactive",
                                          PhysActive == "Yes" ~ "Active")),
         PhysActive = factor(PhysActive, levels = c("Active", "Inactive")),
         DaysMHBad_most = as_factor(case_when(DaysMentHlthBad < 10 ~ "No",
                                              DaysMentHlthBad >= 10 ~ "Yes")),
         DaysMHBad_most = factor(DaysMHBad_most, levels = c("No", "Yes"))) %>% 
  rename(Depress_Freq = Depressed, Sex = Gender, DaysMHBad_count = DaysMentHlthBad, Sleep_Trouble = SleepTrouble) %>% 
  select(ID, SurveyYr, Age, Sex, Race_Eth, Diabetes, Depress_Freq, PhysActive, DaysMHBad_count, DaysMHBad_most, Sleep_Trouble) %>%   
  filter(SurveyYr == "2011_12", Age > 12) %>% 
  filter(if_all(everything(), ~!is.na(.))) %>% 
  select(-SurveyYr)
```

class: middle, inverse

# What makes a count outcome a count?


---
# Count outcomes 

Count outcomes describe how many of an outcome are present, or how often an outcome occurs (i.e., how many of an outcome are present *in a given timeframe*). The latter are often called *rates*.


--
Counts are numeric like continuous outcomes, but always have a **positive** value. 


--
In addition, a distribution of counts is:


--
- Usually **skewed**, meaning that some values are much more common than others.


--
- Often **overdispersed**, which means the counts vary more than would be expected.


--
Counts and rates require analyses that account for these properties.  


---
# Count data

Let's look at `DaysMHBad_count`, the number of days per month a participant reports experiencing poor mental health.


--
```{r, warning=FALSE, echo=FALSE}
NHANES_data1112 %>% 
  ggplot(aes(DaysMHBad_count)) +
  geom_histogram(binwidth = 1)
```

---
# Closer-to-normally-distributed data

Contrast with `SleepHrsNight`, the self-reported number of hours of sleep a participant usually gets.


--
```{r, warning=FALSE, echo=FALSE}
NHANESraw %>% 
  ggplot(aes(SleepHrsNight)) +
  geom_histogram(binwidth = 0.5)
```


---
# Options for analysing count data


--
*Linear regression:* Count outcome variables are sometimes log-transformed and analyzed using OLS regression. 


--
- Many issues in addition to violating model assumptions, including biased estimates and loss of data because it is necessary to take the log of zero (which is undefined).


--
*Poisson regression:* Often used for modeling count data. 


--
*Negative binomial regression:* Similar to Poisson regression, but relaxes a restrictive assumption (to be discussed in a few slides).


--
*Zero-inflated regression model:* Used to account for excess zeros produced by a different process from "true" zeros. 

---
class: middle, inverse

# Analyzing count data

---
# Distributions for counts

When analyzing dichotomous outcomes and count outcomes, we use forms of the binomial distribution, which is the probability distribution of one or more "trials" that can result in one of two outcomes. 


--
- An example of one trial is a single flip of a coin that can result in a heads or a tails. The result of this trial can be described with a single datapoint indicating whether the outcome was heads (or tails, if that was our interest).


--
In logistic regression, our outcome data *also* consists of a single value - whether a participant has diabetes, whether a person is dead, whether a student is absent. This is like saying we have a single trial for each participant. 


--
- So, if we're interested in the relationship between the independent variable(s) and the chances of having one of the two outcomes of that one trial (over many participants), we can use a Bernoulli distribution. This is a form of the binomial distribution that is limited to only one trial. 


---
# Distributions for counts

The chance of having the outcome across more than one trial (e.g., the probability of heads across 5 tosses) follows the binomial distribution. Notice that we now have two datapoints: the trial outcome (heads or tails), and how many trials occurred (5). 


--
One way of thinking of this difference is it shifts the focus from the outcome of a trial (whether it was heads) to counting how many trials resulted in the outcome (how often it was heads).


--
When might this difference apply to the research setting? 


--
Perhaps we're not interested in the relationship between an independent variable and *having* the outcome, but instead its relationship with **how many times** the outcome occurs in a certain population, or over a certain timeframe.


---
# Distributions for counts

In research where the outcome is how many or how often an outcome occurs, the research question is often focused on an outcome that is relatively rare or infrequent. In other words, the research question is not usually about something that happens (nearly) all of the time or to (almost) everyone. Some examples:


--
- Number of absences in a term (most students have few or zero absences)


--
- Number of hospitalizations in a year (most people will not have been hospitalized)


--
- Number of days per month a participant reported having little interest in usual activities (most participants report few or no days with little interest)


--
The resulting distribution of counts is skewed toward 0, and one probability distribution we can use in this situation is the Poisson distribution. 


---
# Distributions for counts

The Poisson distribution is a special case of the binomial distribution, where we have a large number of trials but the outcome of interest occurs infrequently. Another option is the negative binomial distribution. What's the difference? 


--
Poisson assumes the average (mean) number of counts is equal to how much variability there is in the counts. In practice, count data are often overdispersed, meaning there is a greater amount of variability than the mean. 


--
- If there is actually much more variation than what is expected given the Poisson distribution, then we end up with an underestimate of the amount of variation in our model. This results in biased standard errors, and therefore biased p-values and confidence intervals.


--
Negative binomial regression includes a parameter to model the amount of dispersion, which can then be used to adjust error estimates. 


--
Because we're especially concerned about the impact of overdispersion on the amount of error, we will want to examine whether overdispersion is present in the model residuals. This is similar to linear regression, where our main concern is whether the residuals are normally distributed.  


---
# Assessing variability

We can get a preliminary sense of whether overdispersion is present by comparing the mean and variance of the `DaysMHBad_count` variable we looked at earlier. Here we'll limit the data to participants 16 or older because the independent variable we'll look at shortly was not measured in participants under 16.


--
```{r}
NHANES_data1112 %>% 
  filter(Age >= 16) %>% 
  summarize(mean = mean(DaysMHBad_count),
            variance = var(DaysMHBad_count))
```


--
The variance of the counts far exceeds the mean, suggesting overdispersion. We'll formally assess overdispersion of model *residuals* once we've fitted our models. 


--
This said, these values are a good indication that we should go with negative binomial regression, but we'll compare it against a Poisson regression model to confirm. 

---
# Fitting a model

Here, we'll look at whether there is a relationship between participants' self-reported sleep quality (`Sleep_Trouble`) and the number of days per month they have poor mental health (`DaysMHBad_count`). To fit a negative binomial model we'll use the `glm.nb` function from the MASS package (included with R).

--
```{r}
library(MASS)
mod_1 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble, data = NHANES_data1112)
```


--
Fitting a comparable Poisson model for a comparison of fit. 

```{r}
mod_1b <- glm(DaysMHBad_count ~ Sleep_Trouble, family = "poisson",
              data = NHANES_data1112)
```

---
# Fitting a model

--
.pull-left[
**Deviance:**

```{r}
mod_1b$deviance # Poisson
mod_1$deviance # Neg Binom
```
]


--
.pull-right[
**AIC:**

```{r}
mod_1b$aic # Poisson
mod_1$aic # Neg Binom
```
]


--
And most critically, we can see that the Poisson gave us much smaller standard errors, which would produce artificially narrow confidence intervals. 

```{r}
summary(mod_1b)$coefficients[2, "Std. Error"] # Poisson
summary(mod_1)$coefficients[2, "Std. Error"] # Neg Binom
```


---
# Fitting a model

We can also look at whether the negative binomial model better accounts for overdispersion. We'll use the DHARMa package again. 


--
```{r}
mod_1_residuals <- simulateResiduals(mod_1)
testDispersion(mod_1_residuals, 
               alternative = "greater", plot = F)
```


--
Compared with the Poisson:

```{r, echo=FALSE, include=FALSE}
mod_1b_residuals <- simulateResiduals(mod_1b)
mod_1b_residuals_p <- testDispersion(mod_1b_residuals, 
                                     alternative = "greater", plot = F)
```


--
.pull-left[
```{r}
mod_1b_residuals_p$statistic
```
]


--
.pull-right[
```{r}
mod_1b_residuals_p$p.value
```
]

---
# Basic interpretaton 

Like logistic regression, we have to exponentiate the model coefficients to interpret the results.


--
```{r}
mod_1 %>% 
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)
```


--
With counts, the exponentiated coefficient is a **rate ratio**. Here, it tells us that:


--
- Compared with participants who do not have trouble sleeping, participants who have trouble sleeping on average experience 2.13 times as many days per month with poor mental health. 


--
- On average, participants who have trouble sleeping experience 113% more poor mental health days each month than participants who do not have trouble sleeping.

---
class: middle, inverse

# From here, we proceed like logistic regression...


---
# Adding covariates

Adding `Age` as a covariate:

```{r}
mod_2 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age, 
                data = NHANES_data1112)
anova(mod_1, mod_2, test ="Chisq")
```


--
```{r}
mod_1$aic
mod_2$aic
```

---
# Adding covariates

Adding `Sex` as a covariate:

```{r}
mod_3 <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age + Sex, 
                data = NHANES_data1112)
anova(mod_2, mod_3, test ="Chisq")
```


--
```{r}
mod_2$aic
mod_3$aic
```

---
# Adding an interaction

```{r}
mod_3_int <- glm.nb(DaysMHBad_count ~ Sleep_Trouble + Age + Sex + 
                      Sleep_Trouble:Sex, data = NHANES_data1112)
```


--
```{r}
mod_3_int %>% 
  broom::tidy() # Just evaluating significance of the interaction
```

---
# Interpreting an interaction

We can interpret the interaction using predicted *counts*, just like we used predicted probabilities in logistic regression.


--
```{r}
# using the ggeffects package
mod_3_int_probs <- ggeffect(mod_3_int,
                            type = "fe",
                            terms = c("Sleep_Trouble", "Sex"))
```

---
# Interpreting an interaction

We can interpret the interaction using predicted *counts*, just like we used predicted probabilities in logistic regression.

```{r}
print(mod_3_int_probs)
```

---
# Interpreting an interaction

```{r}
plot(mod_3_int_probs)
```

---
# Interpreting an interaction

Female and male participants with sleeping trouble would be expected to have a similar number of poor mental health days each month. 


--
In contrast, among participants who did not report sleeping trouble, female participants would be expected to have significantly more poor mental health days each month than male participants.


--
This suggests that other factors aside from sleep quality may contribute to the number of poor mental health days participants experience each month, particularly for female participants.

---
# Assumptions and diagnostics

We can use the same tools to assess model assumptions as we used in logistic regression.  

--
```{r}
mod_3_int_residuals <- simulateResiduals(mod_3_int) # From DHARMa
plot(mod_3_int_residuals)
```

---
# Assumptions and diagnostics

We can also formally test for zero inflation, again using DHARMa:

```{r}
testZeroInflation(mod_3_int_residuals, plot = FALSE)
```

---
# Assumptions and diagnostics

Checking outliers and multicollinearity visually using the `check_model()` function from the *performance* package.

```{r}
performance::check_model(mod_3_int, check = c("outliers", "vif"))
```

---
# To do's

### Assignments

- Quiz 2 due Friday - Available tomorrow (Wed) morning.

- Assignment 2 due May 11 (previously May 9) - Available after class Thursday.







