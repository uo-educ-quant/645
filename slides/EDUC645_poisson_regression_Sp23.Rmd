---
title: "Count Outcomes and Poisson Regression"
subtitle: "EDUC 645 (Spring 2023)"
#author:
#date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ['default', 'uo', 'ki-fonts', 'my_custom.css', 'xaringanthemer.css']
    # self_contained: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  editor_options: 
  chunk_output_type: console
---

```{R, setup, include = F}
library(pacman)
p_load(NHANES, easystats, emmeans, DHARMa, ggeffects,
       here, tidyverse, ggplot2, xaringan, knitr, kableExtra, foreign, broom, xaringanthemer, reshape2, lfe, arsenal, ggpubr, stargazer, fixest, gtsummary, huxtable, aod)

i_am("slides/EDUC645_poisson_regression_Sp23.rmd")

extra_css <- list(
  ".red"   = list(color = "red"),
  ".blue"  =list(color = "blue"),
  ".green" = list(color = "#8bb174"),
  ".purple" = list(color = "#6A5ACD"),
  ".red-pink" = list(color= "#e64173"),
  ".grey-light" = list(color= "grey70"),
  ".slate" = list(color="#314f4f"),
  ".small" = list("font-size" = "90%"))

write_extra_css(css = extra_css, outfile = "my_custom.css")

# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 5,
  fig.width = 8,
  warning = F,
  message = F
)

NHANES_data1112 <- NHANES::NHANES %>% 
  select(ID, SurveyYr, Gender, Age, AgeDecade, Race3, Education, Poverty, Diabetes, DaysMentHlthBad, Depressed, PhysActive) %>% 
  mutate(Race_Eth = as_factor(case_when(Race3 == "Mexican" | Race3 == "Hispanic" ~ "Hispanic/Latino",
                                        TRUE ~ Race3)),
         PhysActive = as_factor(case_when(PhysActive == "No" ~ "Inactive",
                                          PhysActive == "Yes" ~ "Active")),
         PhysActive = factor(PhysActive, levels = c("Active", "Inactive")),
         DaysMHBad_most = as_factor(case_when(DaysMentHlthBad < 10 ~ "No",
                                              DaysMentHlthBad >= 10 ~ "Yes")),
         DaysMHBad_most = factor(DaysMHBad_most, levels = c("No", "Yes"))) %>% 
  rename(Depress_Freq = Depressed, Sex = Gender, DaysMHBad_count = DaysMentHlthBad) %>% 
  select(ID, SurveyYr, Age, Sex, Race_Eth, Diabetes, Depress_Freq, PhysActive, DaysMHBad_count, DaysMHBad_most) %>%   filter(SurveyYr == "2011_12", Age > 12) %>% 
  filter(if_all(everything(), ~!is.na(.))) %>% 
  select(-SurveyYr)
```

class: middle, inverse

# What makes a count outcome a count?


---
# Count outcomes 

Count outcomes describe how many of an outcome are present, or how often an outcome occurs (i.e., how many of an outcome are present *in a given timeframe*). The latter are often called *rates*.


--
Counts are numeric like continuous outcomes, but a distribution of counts:


--
- Is usually **skewed**, meaning that some values are much more common than others.


--
- Is often **overdispersed**, which means the counts vary more than would be expected.


--
Counts and rates require analyses that account for these properties.  


---
# Count data

Let's look at `DaysMHBad_count`, the number of days per month a participant reports experiencing poor mental health.


--
```{r, warning=FALSE, echo=FALSE}
NHANES_data1112 %>% 
  ggplot(aes(DaysMHBad_count)) +
  geom_histogram(binwidth = 1)
```

---
# Closer-to-normally-distributed data

Contrast with the self-reported number of hours of sleep a participant usually gets, `SleepHrsNight`.


--
```{r, warning=FALSE, echo=FALSE}
NHANESraw %>% 
  ggplot(aes(SleepHrsNight)) +
  geom_histogram(binwidth = 0.5)
```


---
# Options for Analysing Count Data


--
*Linear regression:* Count outcome variables are sometimes log-transformed and analyzed using OLS regression. 


--
- Many issues in addition to violating model assumptions, including loss of data because it necessary to take the log of zero (which is undefined) and biased estimates.


--
*Poisson regression:* Often used for modeling count data. 


--
*Negative binomial regression:* Similar to Poisson regression, but relaxes a restrictive assumption (to be discussed in a few slides).


--
*Zero-inflated regression model:* Used to account for excess zeros.

---
class: middle, inverse

# Analyzing Count Data

---
# Distributions for counts

Both logistic and Poisson regression are forms of the binomial distribution, which is the probability distribution of one or more "trials" that can result in one of two outcomes. 


--
- An example of one trial is a single flip of a coin that can result in a heads or a tails. The result of this trial can be described with a single datapoint indicating whether the outcome was heads (or tails, if that was our interest).


--
In logistic regression, our outcome data *also* consists of a single value - whether a participant has diabetes, whether a person is dead, whether a student is absent. This is like saying we have a single trial for each participant. 


--
- So, if we're interested in the relationship between the independent variable(s) and the chances of having one of the two outcomes of that one trial (over many participants), we can use a Bernoulli distribution. This is a form of the binomial distribution that is limited to only one trial. 


---
# Distributions for counts

The chance of having the outcome across more than one trial (e.g., the probability of heads across 5 tosses) follows the binomial distribution. Notice that we now have two datapoints: the trial outcome (heads or tails), and how many trials occurred (5). 


--
One way of thinking of this difference is it shifts the focus from the outcome of a trial (whether it was heads) to counting how many trials resulted in the outcome (how often it was heads).


--
When might this difference apply to the research setting? Perhaps we're not interested in the relationship between an independent variable and *having* the outcome, but instead its relationship with **how many times** the outcome occurs in a certain population, or over a certain timeframe.


---
# Distributions for counts

In research where the outcome is how many or how often an outcome occurs, the research question is often focused on an outcome that is relatively rare or infrequent. In other words, the research question is not usually about something that happens (nearly) all of the time or to (almost) everyone. Some examples:


--
- Number of absences in a term (most students have few or zero absences)


--
- Number of hospitalization in a year (most people will not have been hospitalized)


--
- Number of days per month a participant reported having little interest in usual activities (most participants report few or no days with little interest)


--
The resulting distribution of counts is skewed toward 0, and one probability distribution we can use in this situation is the Poisson. 


---
# Distributions for counts
The Poisson distribution is a special case of the binomial distribution, where we have a large number of trials but the outcome of interest occurs infrequently. Another option is the negative binomial distribution. What's the difference? 


--
- Poisson assumes the average number of counts is equal to how much variability there is in the counts. In practice, count data are often overdispersed, meaning there is a greater amount of variability than the mean. This can bias standard errors, and therefore p-values and confidence intervals.


--
- Negative binomial does not make this assumption. Instead, it aims to model and account for dispersion, potentially making it more versatile. 


---
# Assessing variability

Let's compare the mean and variance of the `DaysMHBad_count` variable we looked at earlier. This was its distribution: 

```{r, warning=FALSE, echo=FALSE}
NHANES_data1112 %>% 
  ggplot(aes(DaysMHBad_count)) +
  geom_histogram(binwidth = 1)
```

---
# Assessing variability

We could see it's very skewed, but is it overdispersed too?


--
```{r}
NHANES_data1112 %>% 
  summarize(mean = mean(DaysMHBad_count),
            variance = var(DaysMHBad_count))
```


--
The variance of the counts far exceeds the mean, which means we very likely have overdispersion.

---
# Fitting a model

Now that we know the data are likely overdispersed, we should proceed with a negative binomial model. We use the `glm.nb` function from the MASS package (built into R). 


--
```{r}
library(MASS)
mod_1 <- glm.nb(DaysMHBad_count ~ PhysActive, data = NHANES_data1112)
```


--
We already know the data likely violate the Poisson assumption of mean = variance, but let's compare this model to a Poisson model to illustrate the impact on fit: 


--
**Deviance:**

```{r}
mod_1b <- glm(DaysMHBad_count ~ PhysActive, family = "poisson",
              data = NHANES_data1112)

mod_1b$null.deviance
mod_1$null.deviance
```

---
# Fitting a model

**AIC:**

```{r}
mod_1b$aic
mod_1$aic
```


--
And most critically, we can see that the Poisson gave us much smaller standard errors, which would produce artificially narrow confidence intervals. 

```{r}
summary(mod_1b)$coefficients[2, "Std. Error"]
summary(mod_1)$coefficients[2, "Std. Error"]
```


---
# Fitting a model

We can also look at whether the negative binomial model better accounts for overdispersion. We'll use the DHARMa package again. 

```{r}
mod_1_residuals <- simulateResiduals(mod_1)
testDispersion(mod_1_residuals, alternative = "greater", plot = F)
```


--
Compared with the Poisson:

```{r, echo=FALSE, include=FALSE}
mod_1b_residuals <- simulateResiduals(mod_1b)
mod_1b_residuals_p <- testDispersion(mod_1b_residuals, alternative = "greater", plot = F)
```

```{r}
mod_1b_residuals_p$p.value
```

---
# Basic interpretaton 

Like logistic regression, we have to exponentiate the model coefficients to interpret the results.


--
```{r}
mod_1 %>% 
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)
```


--
With counts, the exponentiated coefficient is a **rate ratio**. 


--
- Here, it tells us that compared with active participants, inactive participants experienced 1.5 times as many days per month with poor mental health. 

- Inactive participants experienced 50% more poor mental health days per month than active participants.

---
# To Dos

### Assignments
- Quiz 2 due May 5 (available tomorrow morning)